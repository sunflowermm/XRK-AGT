# XRK-AGT æœªæ¥æ¶æ„è§„åˆ’ï¼ˆ2025ï¼‰

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
- [æŠ€æœ¯æ ˆå‡çº§](#æŠ€æœ¯æ ˆå‡çº§)
- [å®ç°æ–¹æ¡ˆ](#å®ç°æ–¹æ¡ˆ)
- [è¿ç§»è®¡åˆ’](#è¿ç§»è®¡åˆ’)
- [ç¤ºä¾‹ä»£ç ](#ç¤ºä¾‹ä»£ç )

---

## æ¦‚è¿°

### æ ¸å¿ƒç›®æ ‡

1. **ç»Ÿä¸€æ¥å£è°ƒç”¨**ï¼šä¸»æœåŠ¡ç«¯ï¼ˆNode.jsï¼‰é€šè¿‡HTTPæ¥å£è¿æ¥Pythonå­æœåŠ¡ç«¯
2. **ç®€åŒ–æ’ä»¶å¼€å‘**ï¼šæ’ä»¶é€šè¿‡Botå¯¹è±¡ç›´æ¥è°ƒç”¨PythonæœåŠ¡ï¼Œæ— éœ€å…³å¿ƒåº•å±‚å®ç°
3. **åˆ©ç”¨Python AIç”Ÿæ€**ï¼šé›†æˆ2025å¹´æœ€æ–°çš„Python AIå·¥å…·å’Œæ¡†æ¶
4. **æå‡æ€§èƒ½**ï¼šå‡å°‘å¤šè½®AIè°ƒç”¨ï¼Œåˆ©ç”¨RAGç­‰æˆç†ŸæŠ€æœ¯

### é—®é¢˜ç°çŠ¶

- âŒ å½“å‰AIæ— æ³•ä½¿ç”¨MCPåè®®ï¼Œéœ€è¦å¤šè½®è°ƒç”¨
- âŒ RAGç­‰AIåŠŸèƒ½åœ¨Nodeç«¯ç”Ÿæ€ä¸æˆç†Ÿ
- âŒ ä»£ç åˆ†æ•£ï¼Œç»´æŠ¤å›°éš¾
- âŒ æ€§èƒ½ç“¶é¢ˆï¼Œå“åº”æ…¢

---

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "å®¢æˆ·ç«¯å±‚"
        A[AIå¹³å°/æ’ä»¶] --> B[Botå¯¹è±¡]
    end
    
    subgraph "Node.jsä¸»æœåŠ¡ç«¯"
        B --> C[HTTPæ¥å£å±‚]
        C --> D[PythonæœåŠ¡ä»£ç†]
        D --> E[HTTPå®¢æˆ·ç«¯]
        C --> F[å·¥ä½œæµç³»ç»Ÿ]
        C --> G[æ’ä»¶ç³»ç»Ÿ]
    end
    
    subgraph "Pythonå­æœåŠ¡ç«¯"
        E --> H[FastAPIè·¯ç”±]
        H --> I[RAGå¼•æ“]
        H --> J[LLMæœåŠ¡]
        H --> K[å‘é‡æ•°æ®åº“]
        H --> L[å·¥å…·æœåŠ¡]
        
        I --> M[LangChain 0.3+]
        I --> N[LlamaIndex]
        J --> O[Ollama/æœ¬åœ°æ¨¡å‹]
        J --> P[OpenAI API]
        K --> Q[ChromaDB/FAISS]
        L --> R[Pythonå·¥å…·åº“]
    end
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#fff4e1
    style H fill:#e8f5e9
    style I fill:#e8f5e9
    style J fill:#e8f5e9
```

### æ•°æ®æµå›¾

```mermaid
sequenceDiagram
    participant Plugin as æ’ä»¶
    participant Bot as Botå¯¹è±¡
    participant API as HTTPæ¥å£
    participant Proxy as Pythonä»£ç†
    participant Python as PythonæœåŠ¡ç«¯
    participant RAG as RAGå¼•æ“
    
    Plugin->>Bot: Bot.callPythonAPI('rag.query', {query: '...'})
    Bot->>API: POST /api/python/rag/query
    API->>Proxy: è½¬å‘è¯·æ±‚åˆ°PythonæœåŠ¡ç«¯
    Proxy->>Python: HTTP POST http://localhost:8000/api/rag/query
    Python->>RAG: è°ƒç”¨RAGå¼•æ“
    RAG->>Python: è¿”å›ç»“æœ
    Python->>Proxy: JSONå“åº”
    Proxy->>API: è¿”å›ç»“æœ
    API->>Bot: è¿”å›ç»“æœ
    Bot->>Plugin: è¿”å›ç»“æ„åŒ–æ•°æ®
```

---

## æŠ€æœ¯æ ˆå‡çº§

### Pythonå­æœåŠ¡ç«¯ï¼ˆ2025æ–°ç‰¹æ€§ï¼‰

#### 1. æ ¸å¿ƒæ¡†æ¶

```python
# FastAPI 0.115+ (2025æœ€æ–°)
- å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–
- æ›´å¥½çš„ç±»å‹æç¤ºæ”¯æŒ
- WebSocketå¢å¼º

# Pydantic v2.5+
- æ€§èƒ½æå‡50%+
- æ›´å¥½çš„éªŒè¯å’Œåºåˆ—åŒ–
- æ”¯æŒJSON Schemaè‡ªåŠ¨ç”Ÿæˆ
```

#### 2. AI/MLæ¡†æ¶

```python
# LangChain 0.3+ (2025)
- LangGraph: å·¥ä½œæµç¼–æ’
- LangServe: APIæœåŠ¡åŒ–
- LangChain Expression Language (LCEL)
- æ›´å¥½çš„RAGæ”¯æŒ

# LlamaIndex 0.10+
- å‘é‡å­˜å‚¨ä¼˜åŒ–
- å¤šæ¨¡æ€æ”¯æŒ
- æ›´å¥½çš„æ£€ç´¢æ€§èƒ½

# Transformers 4.40+
- æ”¯æŒæœ€æ–°æ¨¡å‹ï¼ˆLlama 3.2, Qwen 2.5ç­‰ï¼‰
- é‡åŒ–ä¼˜åŒ–
- æ¨ç†åŠ é€Ÿ

# Ollama (æœ¬åœ°æ¨¡å‹)
- æœ¬åœ°LLMè¿è¡Œ
- æ— éœ€APIå¯†é’¥
- éšç§ä¿æŠ¤
```

#### 3. å‘é‡æ•°æ®åº“

```python
# ChromaDB 0.5+
- æ›´å¥½çš„æ€§èƒ½
- æŒä¹…åŒ–ä¼˜åŒ–
- å¤šç§Ÿæˆ·æ”¯æŒ

# FAISS (Meta)
- é«˜æ€§èƒ½å‘é‡æ£€ç´¢
- GPUåŠ é€Ÿæ”¯æŒ

# Qdrant (å¯é€‰)
- äº‘åŸç”Ÿè®¾è®¡
- æ›´å¥½çš„æ‰©å±•æ€§
```

#### 4. å·¥å…·åº“

```python
# httpx (å¼‚æ­¥HTTPå®¢æˆ·ç«¯)
- æ›´å¥½çš„æ€§èƒ½
- HTTP/2æ”¯æŒ

# aiofiles (å¼‚æ­¥æ–‡ä»¶æ“ä½œ)
- é«˜æ€§èƒ½æ–‡ä»¶I/O

# python-dotenv (é…ç½®ç®¡ç†)
- ç¯å¢ƒå˜é‡ç®¡ç†
```

---

## å®ç°æ–¹æ¡ˆ

### 1. Node.jsç«¯ï¼šPythonæœåŠ¡ä»£ç†

#### 1.1 HTTPæ¥å£å±‚

**æ–‡ä»¶**: `core/http/python.js`

```javascript
import BotUtil from '#utils/botutil.js';
import axios from 'axios';
import cfg from '#infrastructure/config/config.js';

/**
 * Pythonå­æœåŠ¡ç«¯ä»£ç†
 * æä¾›ç»Ÿä¸€çš„æ¥å£è°ƒç”¨PythonæœåŠ¡ç«¯
 */
export default {
  name: 'python',
  dsc: 'Pythonå­æœåŠ¡ç«¯ä»£ç†æ¥å£',
  priority: 100,

  routes: [
    {
      method: 'POST',
      path: '/api/python/:service/:action',
      handler: async (req, res, Bot) => {
        const { service, action } = req.params;
        const pythonUrl = cfg.python?.url || 'http://localhost:8000';
        
        try {
          const response = await axios.post(
            `${pythonUrl}/api/${service}/${action}`,
            req.body,
            {
              timeout: 30000,
              headers: {
                'Content-Type': 'application/json',
                'X-Request-ID': req.headers['x-request-id'] || Date.now().toString()
              }
            }
          );
          
          res.json({
            success: true,
            data: response.data
          });
        } catch (error) {
          BotUtil.makeLog('error', `PythonæœåŠ¡è°ƒç”¨å¤±è´¥: ${error.message}`, 'PythonProxy');
          res.status(error.response?.status || 500).json({
            success: false,
            error: error.message,
            data: error.response?.data
          });
        }
      }
    },
    
    {
      method: 'GET',
      path: '/api/python/health',
      handler: async (req, res, Bot) => {
        const pythonUrl = cfg.python?.url || 'http://localhost:8000';
        try {
          const response = await axios.get(`${pythonUrl}/health`, { timeout: 5000 });
          res.json({ success: true, status: response.data });
        } catch (error) {
          res.status(503).json({ success: false, error: 'PythonæœåŠ¡ä¸å¯ç”¨' });
        }
      }
    }
  ]
};
```

#### 1.2 Botå¯¹è±¡æ‰©å±•

**æ–‡ä»¶**: `src/utils/python-client.js`

```javascript
import axios from 'axios';
import cfg from '#infrastructure/config/config.js';
import BotUtil from '#utils/botutil.js';

/**
 * PythonæœåŠ¡å®¢æˆ·ç«¯
 * ä¾›Botå¯¹è±¡å’Œæ’ä»¶ä½¿ç”¨
 */
export class PythonClient {
  constructor(bot) {
    this.bot = bot;
    this.baseUrl = cfg.python?.url || 'http://localhost:8000';
    this.timeout = cfg.python?.timeout || 30000;
  }

  /**
   * è°ƒç”¨Python API
   * @param {string} service - æœåŠ¡åç§°ï¼ˆå¦‚ï¼šrag, llm, toolsï¼‰
   * @param {string} action - æ“ä½œåç§°ï¼ˆå¦‚ï¼šquery, generate, searchï¼‰
   * @param {Object} params - å‚æ•°
   * @returns {Promise<any>} ç»“æœ
   */
  async call(service, action, params = {}) {
    try {
      const response = await axios.post(
        `${this.baseUrl}/api/${service}/${action}`,
        params,
        {
          timeout: this.timeout,
          headers: {
            'Content-Type': 'application/json',
            'X-Request-ID': `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
          }
        }
      );
      
      return {
        success: true,
        data: response.data
      };
    } catch (error) {
      BotUtil.makeLog('error', `Python APIè°ƒç”¨å¤±è´¥[${service}.${action}]: ${error.message}`, 'PythonClient');
      return {
        success: false,
        error: error.message,
        data: error.response?.data
      };
    }
  }

  /**
   * RAGæŸ¥è¯¢
   */
  async ragQuery(query, options = {}) {
    return this.call('rag', 'query', { query, ...options });
  }

  /**
   * LLMç”Ÿæˆ
   */
  async llmGenerate(prompt, options = {}) {
    return this.call('llm', 'generate', { prompt, ...options });
  }

  /**
   * å‘é‡æœç´¢
   */
  async vectorSearch(query, topK = 5, options = {}) {
    return this.call('vector', 'search', { query, top_k: topK, ...options });
  }

  /**
   * æ–‡æ¡£å¤„ç†
   */
  async documentProcess(filePath, options = {}) {
    return this.call('document', 'process', { file_path: filePath, ...options });
  }
}
```

**åœ¨Botç±»ä¸­é›†æˆ**:

```javascript
// src/bot.js
import { PythonClient } from '#utils/python-client.js';

export default class Bot extends EventEmitter {
  constructor() {
    super();
    // ... å…¶ä»–åˆå§‹åŒ–
    this.python = new PythonClient(this);
  }
}
```

### 2. Pythonå­æœåŠ¡ç«¯å®ç°

#### 2.1 RAGæœåŠ¡

**æ–‡ä»¶**: `subserver/pyserver/apis/rag_api.py`

```python
"""RAGæœåŠ¡API"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List
from core.rag_service import RAGService

router = APIRouter(prefix="/api/rag", tags=["RAG"])

rag_service = RAGService()

class QueryRequest(BaseModel):
    query: str = Field(..., description="æŸ¥è¯¢æ–‡æœ¬")
    top_k: int = Field(5, ge=1, le=50, description="è¿”å›ç»“æœæ•°é‡")
    collection: Optional[str] = Field(None, description="é›†åˆåç§°")
    filter: Optional[dict] = Field(None, description="è¿‡æ»¤æ¡ä»¶")

class QueryResponse(BaseModel):
    query: str
    results: List[dict]
    total: int
    time_ms: float

@router.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """RAGæŸ¥è¯¢æ¥å£"""
    try:
        results = await rag_service.query(
            query=request.query,
            top_k=request.top_k,
            collection=request.collection,
            filter=request.filter
        )
        return QueryResponse(
            query=request.query,
            results=results,
            total=len(results),
            time_ms=rag_service.last_query_time
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/index")
async def index_document(file_path: str, collection: str = "default"):
    """ç´¢å¼•æ–‡æ¡£"""
    try:
        result = await rag_service.index_document(file_path, collection)
        return {"success": True, "document_id": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 2.2 RAGæœåŠ¡å®ç°ï¼ˆä½¿ç”¨LangChain 0.3+ï¼‰

**æ–‡ä»¶**: `subserver/pyserver/core/rag_service.py`

```python
"""RAGæœåŠ¡å®ç°ï¼ˆä½¿ç”¨LangChain 0.3+ï¼‰"""
import time
from typing import List, Optional, Dict
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, PyPDFLoader
import chromadb

class RAGService:
    """RAGæœåŠ¡ï¼ˆä½¿ç”¨LangChain 0.3+ï¼‰"""
    
    def __init__(self):
        # ä½¿ç”¨Ollamaæœ¬åœ°åµŒå…¥æ¨¡å‹ï¼ˆæˆ–OpenAIï¼‰
        self.embeddings = OllamaEmbeddings(model="nomic-embed-text")
        
        # ChromaDBå‘é‡å­˜å‚¨
        self.vectorstore = Chroma(
            collection_name="documents",
            embedding_function=self.embeddings,
            persist_directory="./data/chroma"
        )
        
        # LLMï¼ˆæœ¬åœ°Ollamaæˆ–OpenAIï¼‰
        self.llm = Ollama(model="llama3.2")
        
        # æ£€ç´¢é“¾
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 5}),
            return_source_documents=True
        )
        
        self.last_query_time = 0.0
    
    async def query(self, query: str, top_k: int = 5, collection: Optional[str] = None, filter: Optional[Dict] = None) -> List[Dict]:
        """RAGæŸ¥è¯¢"""
        start_time = time.time()
        
        # ä½¿ç”¨LangChainæ£€ç´¢é“¾
        result = self.qa_chain.invoke({"query": query})
        
        # æ ¼å¼åŒ–ç»“æœ
        results = []
        for doc in result.get("source_documents", []):
            results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": 1.0  # LangChainä¸ç›´æ¥æä¾›åˆ†æ•°
            })
        
        self.last_query_time = (time.time() - start_time) * 1000
        
        return results[:top_k]
    
    async def index_document(self, file_path: str, collection: str = "default") -> str:
        """ç´¢å¼•æ–‡æ¡£"""
        # åŠ è½½æ–‡æ¡£
        if file_path.endswith('.pdf'):
            loader = PyPDFLoader(file_path)
        else:
            loader = TextLoader(file_path)
        
        documents = loader.load()
        
        # æ–‡æœ¬åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)
        
        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        self.vectorstore.add_documents(splits)
        
        return f"indexed_{len(splits)}_chunks"
```

#### 2.3 LLMæœåŠ¡

**æ–‡ä»¶**: `subserver/pyserver/apis/llm_api.py`

```python
"""LLMæœåŠ¡API"""
from fastapi import APIRouter
from pydantic import BaseModel
from core.llm_service import LLMService

router = APIRouter(prefix="/api/llm", tags=["LLM"])

llm_service = LLMService()

class GenerateRequest(BaseModel):
    prompt: str
    model: str = "llama3.2"
    temperature: float = 0.7
    max_tokens: int = 1000

@router.post("/generate")
async def generate(request: GenerateRequest):
    """ç”Ÿæˆæ–‡æœ¬"""
    result = await llm_service.generate(
        prompt=request.prompt,
        model=request.model,
        temperature=request.temperature,
        max_tokens=request.max_tokens
    )
    return {"success": True, "text": result}
```

#### 2.4 APIæ³¨å†Œ

**æ–‡ä»¶**: `subserver/pyserver/core/loader.py`

```python
"""APIåŠ è½½å™¨"""
from fastapi import FastAPI
from apis.rag_api import router as rag_router
from apis.llm_api import router as llm_router

class ApiLoader:
    @staticmethod
    async def load_all(app: FastAPI):
        """åŠ è½½æ‰€æœ‰API"""
        app.include_router(rag_router)
        app.include_router(llm_router)
        # ... å…¶ä»–API
```

### 3. æ’ä»¶ä½¿ç”¨ç¤ºä¾‹

**æ–‡ä»¶**: `core/plugin/example/rag_example.js`

```javascript
/**
 * RAGæ’ä»¶ç¤ºä¾‹
 * ä½¿ç”¨Botå¯¹è±¡è°ƒç”¨PythonæœåŠ¡ç«¯
 */
export default {
  name: 'rag_example',
  dsc: 'RAGåŠŸèƒ½ç¤ºä¾‹æ’ä»¶',
  
  async onMessage(e, Bot) {
    const text = e.message;
    
    // ä½¿ç”¨Botå¯¹è±¡è°ƒç”¨Python RAGæœåŠ¡
    const result = await Bot.python.ragQuery(text, {
      top_k: 5,
      collection: 'documents'
    });
    
    if (result.success) {
      const answers = result.data.results.map(r => r.content).join('\n\n');
      await Bot.reply(e, `RAGæŸ¥è¯¢ç»“æœï¼š\n${answers}`);
    } else {
      await Bot.reply(e, `æŸ¥è¯¢å¤±è´¥ï¼š${result.error}`);
    }
  }
};
```

---

## è¿ç§»è®¡åˆ’

### é˜¶æ®µ1ï¼šåŸºç¡€è®¾æ–½æ­å»ºï¼ˆ1-2å‘¨ï¼‰

```mermaid
gantt
    title è¿ç§»è®¡åˆ’
    dateFormat  YYYY-MM-DD
    section åŸºç¡€è®¾æ–½
    PythonæœåŠ¡ç«¯æ¡†æ¶æ­å»º    :a1, 2025-01-15, 3d
    HTTPä»£ç†æ¥å£å®ç°        :a2, after a1, 2d
    Botå¯¹è±¡æ‰©å±•            :a3, after a1, 2d
    section RAGæœåŠ¡
    LangChainé›†æˆ          :b1, after a1, 5d
    ChromaDBé…ç½®           :b2, after b1, 2d
    RAG APIå®ç°            :b3, after b2, 3d
    section æµ‹è¯•
    å•å…ƒæµ‹è¯•               :c1, after b3, 3d
    é›†æˆæµ‹è¯•               :c2, after c1, 2d
```

### é˜¶æ®µ2ï¼šæ ¸å¿ƒåŠŸèƒ½è¿ç§»ï¼ˆ2-3å‘¨ï¼‰

- âœ… RAGåŠŸèƒ½è¿ç§»åˆ°Pythonç«¯
- âœ… LLMæœåŠ¡è¿ç§»åˆ°Pythonç«¯
- âœ… å‘é‡æ•°æ®åº“é›†æˆ
- âœ… æ–‡æ¡£å¤„ç†åŠŸèƒ½

### é˜¶æ®µ3ï¼šä¼˜åŒ–å’Œæ‰©å±•ï¼ˆæŒç»­ï¼‰

- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… ç¼“å­˜æœºåˆ¶
- âœ… ç›‘æ§å’Œæ—¥å¿—
- âœ… æ›´å¤šAIåŠŸèƒ½é›†æˆ

---

## é…ç½®ç¤ºä¾‹

### Node.jsé…ç½®

**æ–‡ä»¶**: `config/default_config/python.yaml`

```yaml
python:
  enabled: true
  url: "http://localhost:8000"
  timeout: 30000
  retry:
    max_attempts: 3
    delay: 1000
  health_check:
    interval: 5000
    timeout: 3000
```

### Pythoné…ç½®

**æ–‡ä»¶**: `subserver/pyserver/config.yaml`

```yaml
server:
  host: "0.0.0.0"
  port: 8000
  reload: false

rag:
  embeddings:
    provider: "ollama"  # ollama | openai | local
    model: "nomic-embed-text"
  llm:
    provider: "ollama"  # ollama | openai
    model: "llama3.2"
  vectorstore:
    type: "chroma"
    persist_directory: "./data/chroma"
  chunk_size: 1000
  chunk_overlap: 200

llm:
  default_model: "llama3.2"
  temperature: 0.7
  max_tokens: 2000
```

---

## ä¼˜åŠ¿æ€»ç»“

### 1. æ€§èƒ½æå‡

- âœ… **å•æ¬¡è°ƒç”¨**ï¼šå‡å°‘å¤šè½®AIè°ƒç”¨ï¼Œä¸€æ¬¡å®Œæˆ
- âœ… **å¼‚æ­¥å¤„ç†**ï¼šPythonå¼‚æ­¥æ¡†æ¶æ€§èƒ½ä¼˜å¼‚
- âœ… **æœ¬åœ°æ¨¡å‹**ï¼šOllamaæœ¬åœ°è¿è¡Œï¼Œæ— éœ€APIé™åˆ¶

### 2. ç”Ÿæ€ä¼˜åŠ¿

- âœ… **æˆç†Ÿå·¥å…·**ï¼šLangChainã€LlamaIndexç­‰æˆç†Ÿæ¡†æ¶
- âœ… **ä¸°å¯Œæ¨¡å‹**ï¼šæ”¯æŒå„ç§å¼€æºå’Œå•†ä¸šæ¨¡å‹
- âœ… **å‘é‡æ•°æ®åº“**ï¼šChromaDBã€FAISSç­‰é«˜æ€§èƒ½æ–¹æ¡ˆ

### 3. å¼€å‘ä½“éªŒ

- âœ… **ç»Ÿä¸€æ¥å£**ï¼šBotå¯¹è±¡ç»Ÿä¸€è°ƒç”¨
- âœ… **ç±»å‹å®‰å…¨**ï¼šPydanticæä¾›ç±»å‹éªŒè¯
- âœ… **æ˜“äºæ‰©å±•**ï¼šFastAPIè·¯ç”±ç³»ç»Ÿçµæ´»

### 4. ç»´æŠ¤æ€§

- âœ… **ä»£ç åˆ†ç¦»**ï¼šNodeç«¯å’ŒPythonç«¯èŒè´£æ¸…æ™°
- âœ… **ç‹¬ç«‹éƒ¨ç½²**ï¼šPythonæœåŠ¡å¯ç‹¬ç«‹æ‰©å±•
- âœ… **æŠ€æœ¯é€‰å‹**ï¼šä½¿ç”¨æœ€é€‚åˆçš„å·¥å…·

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… æ­å»ºPythonæœåŠ¡ç«¯åŸºç¡€æ¡†æ¶
2. âœ… å®ç°HTTPä»£ç†æ¥å£
3. âœ… é›†æˆLangChain RAGæœåŠ¡
4. âœ… ç¼–å†™ç¤ºä¾‹æ’ä»¶
5. âœ… æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2025-01-13  
**ç»´æŠ¤è€…**: XRK-AGT Team
