# XRK-AGT æœªæ¥æ¶æ„è§„åˆ’ï¼ˆ2026ï¼‰

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
- [æŠ€æœ¯æ ˆå‡çº§](#æŠ€æœ¯æ ˆå‡çº§)
- [å®ç°æ–¹æ¡ˆ](#å®ç°æ–¹æ¡ˆ)
- [è¿ç§»è®¡åˆ’](#è¿ç§»è®¡åˆ’)
- [ç¤ºä¾‹ä»£ç ](#ç¤ºä¾‹ä»£ç )

---

## æ¦‚è¿°

### æ ¸å¿ƒç›®æ ‡

1. **é«˜æ€§èƒ½å†…æœåŠ¡è°ƒç”¨**ï¼šPythonä½œä¸ºå­æœåŠ¡ç«¯ï¼Œä»…é¢å‘Node.jsä¸»æœåŠ¡ç«¯ï¼Œä¸æš´éœ²ç»™å¤–éƒ¨ï¼Œä¸“æ³¨ä¼˜åŒ–å»¶è¿Ÿå®ç°0å»¶è¿Ÿå“åº”
2. **ç®€åŒ–æ’ä»¶å¼€å‘**ï¼šæ’ä»¶é€šè¿‡Botå¯¹è±¡ç›´æ¥è°ƒç”¨PythonæœåŠ¡ï¼Œæ— éœ€å…³å¿ƒåº•å±‚å®ç°
3. **åˆ©ç”¨Python AIç”Ÿæ€**ï¼šé›†æˆ2026å¹´æœ€æ–°çš„Python AIå·¥å…·å’Œæ¡†æ¶ï¼ˆLangChainã€Ollamaç­‰ï¼‰
4. **ä»£ç ç²¾ç®€**ï¼šåˆ é™¤Node.jsç«¯å†—ä½™çš„AIåŠŸèƒ½ä»£ç ï¼Œè¿ç§»åˆ°Pythonç«¯
5. **æå‡æ€§èƒ½**ï¼šä½¿ç”¨LangChain Agentå‡å°‘å¤šè½®AIè°ƒç”¨ï¼Œåˆ©ç”¨RAGç­‰æˆç†ŸæŠ€æœ¯

### é—®é¢˜ç°çŠ¶

- âš ï¸ å½“å‰AIéƒ¨åˆ†åŠŸèƒ½æ— æ³•ä½¿ç”¨MCPåè®®ï¼Œéœ€è¦å¤šè½®è°ƒç”¨ï¼ˆæ­£åœ¨å®Œå–„MCPæ”¯æŒï¼‰
- âŒ RAGç­‰AIåŠŸèƒ½åœ¨Nodeç«¯ç”Ÿæ€ä¸æˆç†Ÿï¼ˆBM25ç®—æ³•æ•ˆæœå·®ï¼‰
- âŒ Node.jsç«¯æœ‰å¤§é‡å†—ä½™çš„Embeddingå’Œå‘é‡æ£€ç´¢ä»£ç 
- âŒ ä»£ç åˆ†æ•£ï¼Œç»´æŠ¤å›°éš¾
- âŒ æ€§èƒ½ç“¶é¢ˆï¼Œå“åº”æ…¢

### è§£å†³æ–¹æ¡ˆ

- âœ… **è¿ç§»AIåŠŸèƒ½åˆ°Pythonç«¯**ï¼šä½¿ç”¨LangChainç”Ÿæ€ï¼ˆRAGã€LLMã€å‘é‡æ•°æ®åº“ï¼‰
- âœ… **åˆ é™¤Node.jsç«¯å†—ä½™ä»£ç **ï¼šåˆ é™¤Embeddingã€BM25ã€å‘é‡æ£€ç´¢ç­‰ä»£ç 
- âœ… **ä¿ç•™ä¸šåŠ¡é€»è¾‘å±‚**ï¼šå·¥ä½œæµã€æ’ä»¶ã€äº‹ä»¶ç³»ç»Ÿä¿ç•™åœ¨Node.jsç«¯
- âœ… **ç»Ÿä¸€è°ƒç”¨æ¥å£**ï¼šé€šè¿‡Botå¯¹è±¡ç»Ÿä¸€è°ƒç”¨Pythonå­æœåŠ¡ï¼Œä¼˜åŒ–å»¶è¿Ÿå®ç°è¿‘é›¶å»¶è¿Ÿå“åº”

---

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph Client["å®¢æˆ·ç«¯å±‚"]
        A["AIå¹³å°/æ’ä»¶"] --> B["Botå¯¹è±¡"]
    end
    
    subgraph NodeJS["Node.jsä¸»æœåŠ¡ç«¯"]
        B --> C["å·¥ä½œæµç³»ç»Ÿ"]
        B --> D["æ’ä»¶ç³»ç»Ÿ"]
        C --> E["PythonæœåŠ¡<br/>ä»£ç†"]
        D --> E
        E --> F["HTTPå®¢æˆ·ç«¯<br/>æœ¬åœ°è°ƒç”¨"]
    end
    
    subgraph Python["Pythonå­æœåŠ¡ç«¯<br/>å†…éƒ¨æœåŠ¡<br/>ä¸å¯¹å¤–æš´éœ²"]
        F --> G["FastAPIè·¯ç”±"]
        G --> H["RAGå¼•æ“"]
        G --> I["LLMæœåŠ¡"]
        G --> J["å‘é‡æ•°æ®åº“"]
        
        H --> K["LangChain<br/>0.3+"]
        H --> L["LlamaIndex"]
        I --> M["APIä¼˜å…ˆ<br/>OpenAI<br/>VolcEngine"]
        I --> N["æœ¬åœ°é™çº§<br/>Ollama"]
        J --> O["ChromaDB"]
        J --> P["FAISS"]
    end
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style E fill:#fff4e1
    style G fill:#e8f5e9
    style H fill:#e8f5e9
    style I fill:#e8f5e9
    style J fill:#e8f5e9
```

### æ•°æ®æµå›¾

```mermaid
sequenceDiagram
    participant Plugin as æ’ä»¶
    participant Bot as Botå¯¹è±¡
    participant Proxy as Pythonä»£ç†<br/>æœ¬åœ°HTTPå®¢æˆ·ç«¯
    participant Python as Pythonå­æœåŠ¡ç«¯<br/>localhost:8000
    participant LangChain as LangChain RAG
    
    Plugin->>Bot: Bot.python.ragQuery<br/>('æŸ¥è¯¢å†…å®¹')
    Bot->>Proxy: è°ƒç”¨PythonæœåŠ¡
    Proxy->>Python: HTTP POST<br/>localhost:8000/api/rag/query<br/>æœ¬åœ°è°ƒç”¨ï¼Œä¼˜åŒ–å»¶è¿Ÿ
    Python->>LangChain: è°ƒç”¨LangChain<br/>RAGæœåŠ¡
    LangChain->>LangChain: å‘é‡æ£€ç´¢ +<br/>LLMç”Ÿæˆ
    LangChain->>Python: è¿”å›ç»“æœ
    Python->>Proxy: JSONå“åº”
    Proxy->>Bot: è¿”å›ç»“æœ
    Bot->>Plugin: è¿”å›ç»“æ„åŒ–æ•°æ®
    
    Note over Proxy,Python: å†…éƒ¨æœåŠ¡è°ƒç”¨<br/>ä¸å¯¹å¤–æš´éœ²<br/>ä¸“æ³¨ä¼˜åŒ–å»¶è¿Ÿ<br/>å®ç°0å»¶è¿Ÿå“åº”
```

### æ¶æ„å¯¹æ¯”ï¼ˆè¿ç§»å‰åï¼‰

```mermaid
graph TB
    subgraph Before["è¿ç§»å‰<br/>Node.jsç«¯<br/>å†—ä½™"]
        A1["Embeddingç”Ÿæˆ<br/>BM25ç®—æ³•<br/>~200è¡Œ"]
        A2["å‘é‡æ£€ç´¢<br/>Rediså­˜å‚¨<br/>~150è¡Œ"]
        A3["æ–‡æ¡£å¤„ç†<br/>åŸºç¡€åŠŸèƒ½<br/>~100è¡Œ"]
        A4["å·¥ä½œæµç³»ç»Ÿ<br/>ä¿ç•™"]
        A5["æ’ä»¶ç³»ç»Ÿ<br/>ä¿ç•™"]
    end
    
    subgraph After["è¿ç§»å<br/>ç²¾ç®€æ¶æ„"]
        B1["å·¥ä½œæµç³»ç»Ÿ<br/>ä¸šåŠ¡é€»è¾‘<br/>ä¿ç•™"]
        B2["æ’ä»¶ç³»ç»Ÿ<br/>ä¿ç•™"]
        B3["PythonæœåŠ¡<br/>ä»£ç†æ–°å¢"]
        B4["LangChain RAG<br/>å‘é‡æ•°æ®åº“<br/>Pythonç«¯"]
        B5["LangChain Agent<br/>å·¥å…·è°ƒç”¨<br/>Pythonç«¯"]
    end
    
    A1 -.åˆ é™¤~200è¡Œ.-> B4
    A2 -.åˆ é™¤~150è¡Œ.-> B4
    A3 -.åˆ é™¤~100è¡Œ.-> B4
    A4 --> B1
    A5 --> B2
    B1 --> B3
    B2 --> B3
    B3 --> B4
    B3 --> B5
    
    style A1 fill:#ffebee
    style A2 fill:#ffebee
    style A3 fill:#ffebee
    style B4 fill:#e8f5e9
    style B5 fill:#e8f5e9
```

### ä»£ç é‡å¯¹æ¯”

| æ¨¡å— | è¿ç§»å‰ | è¿ç§»å | å˜åŒ– |
|------|--------|--------|------|
| **Node.jsç«¯** | ~15,000è¡Œ | ~12,000è¡Œ | **-3,000è¡Œï¼ˆ-20%ï¼‰** |
| **Pythonç«¯** | ~500è¡Œ | ~3,000è¡Œ | **+2,500è¡Œï¼ˆæ–°å¢ï¼‰** |
| **æ€»è®¡** | ~15,500è¡Œ | ~15,000è¡Œ | **-500è¡Œï¼ˆç²¾ç®€ï¼‰** |

**ä¼˜åŠ¿**ï¼š
- âœ… Node.jsç«¯ä»£ç æ›´ç²¾ç®€ï¼ŒèŒè´£æ›´æ¸…æ™°
- âœ… Pythonç«¯åŠŸèƒ½æ›´å¼ºå¤§ï¼Œä½¿ç”¨æˆç†Ÿç”Ÿæ€
- âœ… æ€»ä½“ä»£ç é‡å‡å°‘ï¼Œç»´æŠ¤æ›´å®¹æ˜“

---

## æŠ€æœ¯æ ˆå‡çº§

### Pythonå­æœåŠ¡ç«¯ï¼ˆ2026æ–°ç‰¹æ€§ï¼‰

#### 1. æ ¸å¿ƒæ¡†æ¶

```python
# FastAPI 0.115+ (2026æœ€æ–°)
- å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–
- æ›´å¥½çš„ç±»å‹æç¤ºæ”¯æŒ
- WebSocketå¢å¼º

# Pydantic v2.5+
- æ€§èƒ½æå‡50%+
- æ›´å¥½çš„éªŒè¯å’Œåºåˆ—åŒ–
- æ”¯æŒJSON Schemaè‡ªåŠ¨ç”Ÿæˆ
```

#### 2. AI/MLæ¡†æ¶

```python
# LangChain 0.3+ (2026)
- LangGraph: å·¥ä½œæµç¼–æ’
- LangServe: APIæœåŠ¡åŒ–
- LangChain Expression Language (LCEL)
- æ›´å¥½çš„RAGæ”¯æŒ

# LlamaIndex 0.10+
- å‘é‡å­˜å‚¨ä¼˜åŒ–
- å¤šæ¨¡æ€æ”¯æŒ
- æ›´å¥½çš„æ£€ç´¢æ€§èƒ½

# Transformers 4.40+
- æ”¯æŒæœ€æ–°æ¨¡å‹ï¼ˆLlama 3.2, Qwen 2.5ç­‰ï¼‰
- é‡åŒ–ä¼˜åŒ–
- æ¨ç†åŠ é€Ÿ

# Ollama (æœ¬åœ°é™çº§æ–¹æ¡ˆ)
- APIä¸å¯ç”¨æ—¶çš„é™çº§é€‰æ‹©
- çº¯æœ¬åœ°ç¯å¢ƒæ”¯æŒ
- éšç§ä¿æŠ¤åœºæ™¯
```

#### 3. å‘é‡æ•°æ®åº“

**ChromaDBï¼ˆä¸»è¦é€‰æ‹©ï¼‰**
- è½»é‡çº§ã€æ˜“äºéƒ¨ç½²
- æŒä¹…åŒ–æ”¯æŒï¼Œæ•°æ®å®‰å…¨å¯é 
- ä¸LangChainæ·±åº¦é›†æˆ
- æ”¯æŒå¤šé›†åˆï¼ˆcollectionsï¼‰ç®¡ç†
- æœ¬åœ°éƒ¨ç½²ï¼Œæ— å¤–éƒ¨ä¾èµ–

**FAISSï¼ˆé«˜æ€§èƒ½åœºæ™¯ï¼‰**
- Metaå¼€æºçš„é«˜æ€§èƒ½å‘é‡æ£€ç´¢åº“
- æ”¯æŒGPUåŠ é€Ÿï¼ˆå¯é€‰ï¼‰
- é€‚åˆå¤§è§„æ¨¡å‘é‡æ£€ç´¢
- éœ€è¦é¢å¤–çš„é›†æˆå·¥ä½œ

**è§„åˆ’**ï¼š
- é»˜è®¤ä½¿ç”¨ChromaDBä½œä¸ºå‘é‡å­˜å‚¨
- æ•°æ®æŒä¹…åŒ–åˆ°æœ¬åœ°ç›®å½•ï¼ˆ`data/chroma`ï¼‰
- æ”¯æŒçŸ¥è¯†åº“ã€è®°å¿†ç³»ç»Ÿç­‰å¤šä¸ªé›†åˆ
- æœªæ¥å¯æ ¹æ®éœ€æ±‚æ‰©å±•FAISSæ”¯æŒ

#### 4. æç¤ºè¯ä¼˜åŒ–æ–¹æ¡ˆ

**é—®é¢˜**ï¼šå·¥ä½œæµç³»ç»Ÿéœ€è¦æ„å»ºå¤§é‡æç¤ºè¯ï¼ˆç³»ç»Ÿæç¤ºè¯ã€å‡½æ•°æç¤ºè¯ã€ä¸Šä¸‹æ–‡ç­‰ï¼‰ï¼Œç›´æ¥æ‹¼æ¥ä¼šå¯¼è‡´tokenæ¶ˆè€—å¤§ã€å“åº”æ…¢ã€‚

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š

1. **æç¤ºè¯æ¨¡æ¿åŒ–**
   - ä½¿ç”¨LangChainçš„`PromptTemplate`ç®¡ç†æ¨¡æ¿
   - åŠ¨æ€å˜é‡æ›¿æ¢ï¼Œé¿å…é‡å¤æ„å»º
   - æ¨¡æ¿ç¼“å­˜ï¼Œå‡å°‘é‡å¤è®¡ç®—

2. **æç¤ºè¯å‹ç¼©**
   - ä½¿ç”¨LangChainçš„`PromptCompressor`å‹ç¼©é•¿æç¤ºè¯
   - ä¿ç•™å…³é”®ä¿¡æ¯ï¼Œå»é™¤å†—ä½™å†…å®¹
   - å¯å‡å°‘30-50%çš„tokenæ¶ˆè€—

3. **åˆ†å±‚æç¤ºè¯æ„å»º**
   - ç³»ç»Ÿæç¤ºè¯ï¼šé™æ€æ¨¡æ¿ï¼Œå¯åŠ¨æ—¶åŠ è½½
   - å‡½æ•°æç¤ºè¯ï¼šæŒ‰éœ€åŠ¨æ€ç”Ÿæˆ
   - ä¸Šä¸‹æ–‡æç¤ºè¯ï¼šä½¿ç”¨RAGæ£€ç´¢ï¼ŒåªåŒ…å«ç›¸å…³å†…å®¹

4. **æç¤ºè¯ç¼“å­˜**
   - ç›¸åŒæŸ¥è¯¢çš„æç¤ºè¯ç¼“å­˜
   - ä½¿ç”¨å“ˆå¸Œå€¼åˆ¤æ–­æ˜¯å¦å‘½ä¸­ç¼“å­˜
   - å‡å°‘é‡å¤çš„æç¤ºè¯æ„å»ºå¼€é”€

**å®ç°ç¤ºä¾‹**ï¼š

```python
# subserver/pyserver/core/prompt_optimizer.py
from langchain.prompts import PromptTemplate
from langchain.prompt_compressor import PromptCompressor
import hashlib
import json

class PromptOptimizer:
    """æç¤ºè¯ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.template_cache = {}
        self.prompt_cache = {}
        self.compressor = PromptCompressor()
    
    def get_template(self, template_name: str, **kwargs) -> str:
        """è·å–æ¨¡æ¿ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{template_name}_{hashlib.md5(json.dumps(kwargs, sort_keys=True).encode()).hexdigest()}"
        if cache_key not in self.template_cache:
            template = PromptTemplate.from_template(self._load_template(template_name))
            self.template_cache[cache_key] = template.format(**kwargs)
        return self.template_cache[cache_key]
    
    def compress_prompt(self, prompt: str, max_tokens: int = 2000) -> str:
        """å‹ç¼©æç¤ºè¯"""
        if len(prompt) <= max_tokens:
            return prompt
        return self.compressor.compress(prompt, max_tokens=max_tokens)
    
    def build_system_prompt(self, functions: list, context: dict) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        # 1. ä½¿ç”¨æ¨¡æ¿
        base_prompt = self.get_template("system_base", **context)
        
        # 2. å‡½æ•°æç¤ºè¯åŠ¨æ€ç”Ÿæˆï¼ˆåªåŒ…å«å¯ç”¨çš„å‡½æ•°ï¼‰
        function_prompts = [f.get("prompt", "") for f in functions if f.get("enabled")]
        functions_text = "\n".join(function_prompts)
        
        # 3. åˆå¹¶å¹¶å‹ç¼©
        full_prompt = f"{base_prompt}\n\nå¯ç”¨å‡½æ•°ï¼š\n{functions_text}"
        return self.compress_prompt(full_prompt, max_tokens=3000)
```

**å¥½å¤„**ï¼š
- âœ… **å‡å°‘tokenæ¶ˆè€—**ï¼šå‹ç¼©å’Œç¼“å­˜å¯å‡å°‘30-50%çš„tokenä½¿ç”¨
- âœ… **æå‡å“åº”é€Ÿåº¦**ï¼šæ¨¡æ¿ç¼“å­˜å’Œåˆ†å±‚æ„å»ºå‡å°‘è®¡ç®—æ—¶é—´
- âœ… **é™ä½APIæˆæœ¬**ï¼šæ›´å°‘çš„tokenæ„å‘³ç€æ›´ä½çš„APIè°ƒç”¨æˆæœ¬
- âœ… **æ›´å¥½çš„æ€§èƒ½**ï¼šä¼˜åŒ–çš„æç¤ºè¯ç»“æ„æå‡LLMç†è§£æ•ˆç‡

**æ”¹åŠ¨è¯´æ˜**ï¼š
- Node.jsç«¯ï¼šå·¥ä½œæµæ„å»ºæç¤ºè¯æ—¶ï¼Œè°ƒç”¨PythonæœåŠ¡çš„æç¤ºè¯ä¼˜åŒ–æ¥å£
- Pythonç«¯ï¼šæ–°å¢`PromptOptimizer`ç±»ï¼Œæä¾›æç¤ºè¯æ¨¡æ¿åŒ–ã€å‹ç¼©ã€ç¼“å­˜åŠŸèƒ½
- æ¥å£ï¼š`POST /api/prompt/optimize` - ä¼˜åŒ–æç¤ºè¯
- æ¥å£ï¼š`POST /api/prompt/build` - æ„å»ºå®Œæ•´æç¤ºè¯

---

## å®ç°æ–¹æ¡ˆ

### 1. Node.jsç«¯ï¼šPythonæœåŠ¡ä»£ç†

#### 1.1 HTTPæ¥å£å±‚

**æ–‡ä»¶**: `core/http/python.js`

```javascript
import BotUtil from '#utils/botutil.js';
import axios from 'axios';
import cfg from '#infrastructure/config/config.js';

/**
 * Pythonå­æœåŠ¡ç«¯ä»£ç†
 * æä¾›ç»Ÿä¸€çš„æ¥å£è°ƒç”¨PythonæœåŠ¡ç«¯
 */
export default {
  name: 'python',
  dsc: 'Pythonå­æœåŠ¡ç«¯ä»£ç†æ¥å£',
  priority: 100,

  routes: [
    {
      method: 'POST',
      path: '/api/python/:service/:action',
      handler: async (req, res, Bot) => {
        const { service, action } = req.params;
        const pythonUrl = cfg.python?.url || 'http://localhost:8000';
        
        try {
          const response = await axios.post(
            `${pythonUrl}/api/${service}/${action}`,
            req.body,
            {
              timeout: 30000,
              headers: {
                'Content-Type': 'application/json',
                'X-Request-ID': req.headers['x-request-id'] || Date.now().toString()
              }
            }
          );
          
          res.json({
            success: true,
            data: response.data
          });
        } catch (error) {
          BotUtil.makeLog('error', `PythonæœåŠ¡è°ƒç”¨å¤±è´¥: ${error.message}`, 'PythonProxy');
          res.status(error.response?.status || 500).json({
            success: false,
            error: error.message,
            data: error.response?.data
          });
        }
      }
    },
    
    {
      method: 'GET',
      path: '/api/python/health',
      handler: async (req, res, Bot) => {
        const pythonUrl = cfg.python?.url || 'http://localhost:8000';
        try {
          const response = await axios.get(`${pythonUrl}/health`, { timeout: 5000 });
          res.json({ success: true, status: response.data });
        } catch (error) {
          res.status(503).json({ success: false, error: 'PythonæœåŠ¡ä¸å¯ç”¨' });
        }
      }
    }
  ]
};
```

#### 1.2 Botå¯¹è±¡æ‰©å±•

**æ–‡ä»¶**: `src/utils/python-client.js`

```javascript
import axios from 'axios';
import cfg from '#infrastructure/config/config.js';
import BotUtil from '#utils/botutil.js';

/**
 * PythonæœåŠ¡å®¢æˆ·ç«¯
 * ä¾›Botå¯¹è±¡å’Œæ’ä»¶ä½¿ç”¨
 */
export class PythonClient {
  constructor(bot) {
    this.bot = bot;
    this.baseUrl = cfg.python?.url || 'http://localhost:8000';
    this.timeout = cfg.python?.timeout || 30000;
  }

  /**
   * è°ƒç”¨Python API
   * @param {string} service - æœåŠ¡åç§°ï¼ˆå¦‚ï¼šrag, llm, toolsï¼‰
   * @param {string} action - æ“ä½œåç§°ï¼ˆå¦‚ï¼šquery, generate, searchï¼‰
   * @param {Object} params - å‚æ•°
   * @returns {Promise<any>} ç»“æœ
   */
  async call(service, action, params = {}) {
    try {
      const response = await axios.post(
        `${this.baseUrl}/api/${service}/${action}`,
        params,
        {
          timeout: this.timeout,
          headers: {
            'Content-Type': 'application/json',
            'X-Request-ID': `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
          }
        }
      );
      
      return {
        success: true,
        data: response.data
      };
    } catch (error) {
      BotUtil.makeLog('error', `Python APIè°ƒç”¨å¤±è´¥[${service}.${action}]: ${error.message}`, 'PythonClient');
      return {
        success: false,
        error: error.message,
        data: error.response?.data
      };
    }
  }

  /**
   * RAGæŸ¥è¯¢
   */
  async ragQuery(query, options = {}) {
    return this.call('rag', 'query', { query, ...options });
  }

  /**
   * LLMç”Ÿæˆ
   */
  async llmGenerate(prompt, options = {}) {
    return this.call('llm', 'generate', { prompt, ...options });
  }

  /**
   * å‘é‡æœç´¢
   */
  async vectorSearch(query, topK = 5, options = {}) {
    return this.call('vector', 'search', { query, top_k: topK, ...options });
  }

  /**
   * æ–‡æ¡£å¤„ç†
   */
  async documentProcess(filePath, options = {}) {
    return this.call('document', 'process', { file_path: filePath, ...options });
  }
}
```

**åœ¨Botç±»ä¸­é›†æˆ**:

```javascript
// src/bot.js
import { PythonClient } from '#utils/python-client.js';

export default class Bot extends EventEmitter {
  constructor() {
    super();
    // ... å…¶ä»–åˆå§‹åŒ–
    this.python = new PythonClient(this);
  }
}
```

### 2. Pythonå­æœåŠ¡ç«¯å®ç°

#### 2.1 RAGæœåŠ¡

**æ–‡ä»¶**: `subserver/pyserver/apis/rag_api.py`

```python
"""RAGæœåŠ¡API"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List
from core.rag_service import RAGService

router = APIRouter(prefix="/api/rag", tags=["RAG"])

rag_service = RAGService()

class QueryRequest(BaseModel):
    query: str = Field(..., description="æŸ¥è¯¢æ–‡æœ¬")
    top_k: int = Field(5, ge=1, le=50, description="è¿”å›ç»“æœæ•°é‡")
    collection: Optional[str] = Field(None, description="é›†åˆåç§°")
    filter: Optional[dict] = Field(None, description="è¿‡æ»¤æ¡ä»¶")

class QueryResponse(BaseModel):
    query: str
    results: List[dict]
    total: int
    time_ms: float

@router.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """RAGæŸ¥è¯¢æ¥å£"""
    try:
        results = await rag_service.query(
            query=request.query,
            top_k=request.top_k,
            collection=request.collection,
            filter=request.filter
        )
        return QueryResponse(
            query=request.query,
            results=results,
            total=len(results),
            time_ms=rag_service.last_query_time
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/index")
async def index_document(file_path: str, collection: str = "default"):
    """ç´¢å¼•æ–‡æ¡£"""
    try:
        result = await rag_service.index_document(file_path, collection)
        return {"success": True, "document_id": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 2.2 RAGæœåŠ¡å®ç°ï¼ˆä½¿ç”¨LangChain 0.3+ï¼‰

**æ–‡ä»¶**: `subserver/pyserver/core/rag_service.py`

```python
"""RAGæœåŠ¡å®ç°ï¼ˆä½¿ç”¨LangChain 0.3+ï¼‰"""
import time
from typing import List, Optional, Dict
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, PyPDFLoader
import chromadb

class RAGService:
    """RAGæœåŠ¡ï¼ˆä½¿ç”¨LangChain 0.3+ï¼‰"""
    
    def __init__(self):
        # Embeddingæ¨¡å‹ï¼šAPIä¼˜å…ˆï¼Œæœ¬åœ°é™çº§
        self.embedding_provider = config.get("embedding", {}).get("provider", "api")
        if self.embedding_provider == "api":
            from langchain_openai import OpenAIEmbeddings
            self.embeddings = OpenAIEmbeddings()
        else:
            from langchain_community.embeddings import OllamaEmbeddings
            self.embeddings = OllamaEmbeddings(model="nomic-embed-text")
        
        # å‘é‡å­˜å‚¨ï¼šæ ¹æ®æ€§èƒ½é€‰æ‹©ChromaDBæˆ–FAISS
        vectorstore_type = config.get("vectorstore", {}).get("type", "chroma")
        if vectorstore_type == "faiss":
            from langchain_community.vectorstores import FAISS
            self.vectorstore = FAISS(embedding_function=self.embeddings)
        else:
            self.vectorstore = Chroma(
                collection_name="documents",
                embedding_function=self.embeddings,
                persist_directory="./data/chroma"
            )
        
        # LLMï¼šAPIä¼˜å…ˆï¼Œæœ¬åœ°é™çº§
        llm_provider = config.get("llm", {}).get("provider", "api")
        if llm_provider == "api":
            from langchain_openai import ChatOpenAI
            self.llm = ChatOpenAI()
        else:
            from langchain_community.llms import Ollama
            self.llm = Ollama(model="llama3.2:7b")
        
        # æ£€ç´¢é“¾
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 5}),
            return_source_documents=True
        )
        
        self.last_query_time = 0.0
    
    async def query(self, query: str, top_k: int = 5, collection: Optional[str] = None, filter: Optional[Dict] = None) -> List[Dict]:
        """RAGæŸ¥è¯¢"""
        start_time = time.time()
        
        # ä½¿ç”¨LangChainæ£€ç´¢é“¾
        result = self.qa_chain.invoke({"query": query})
        
        # æ ¼å¼åŒ–ç»“æœ
        results = []
        for doc in result.get("source_documents", []):
            results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": 1.0  # LangChainä¸ç›´æ¥æä¾›åˆ†æ•°
            })
        
        self.last_query_time = (time.time() - start_time) * 1000
        
        return results[:top_k]
    
    async def index_document(self, file_path: str, collection: str = "default") -> str:
        """ç´¢å¼•æ–‡æ¡£"""
        # åŠ è½½æ–‡æ¡£
        if file_path.endswith('.pdf'):
            loader = PyPDFLoader(file_path)
        else:
            loader = TextLoader(file_path)
        
        documents = loader.load()
        
        # æ–‡æœ¬åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)
        
        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        self.vectorstore.add_documents(splits)
        
        return f"indexed_{len(splits)}_chunks"
```

#### 2.3 LLMæœåŠ¡

**æ–‡ä»¶**: `subserver/pyserver/apis/llm_api.py`

```python
"""LLMæœåŠ¡API"""
from fastapi import APIRouter
from pydantic import BaseModel
from core.llm_service import LLMService

router = APIRouter(prefix="/api/llm", tags=["LLM"])

llm_service = LLMService()

class GenerateRequest(BaseModel):
    prompt: str
    model: str = "llama3.2"
    temperature: float = 0.7
    max_tokens: int = 1000

@router.post("/generate")
async def generate(request: GenerateRequest):
    """ç”Ÿæˆæ–‡æœ¬"""
    result = await llm_service.generate(
        prompt=request.prompt,
        model=request.model,
        temperature=request.temperature,
        max_tokens=request.max_tokens
    )
    return {"success": True, "text": result}
```

#### 2.4 APIæ³¨å†Œ

**æ–‡ä»¶**: `subserver/pyserver/core/loader.py`

```python
"""APIåŠ è½½å™¨"""
from fastapi import FastAPI
from apis.rag_api import router as rag_router
from apis.llm_api import router as llm_router

class ApiLoader:
    @staticmethod
    async def load_all(app: FastAPI):
        """åŠ è½½æ‰€æœ‰API"""
        app.include_router(rag_router)
        app.include_router(llm_router)
        # ... å…¶ä»–API
```

### 3. æ’ä»¶ç³»ç»Ÿè°ƒç”¨å·¥ä½œæµæµç¨‹

#### 3.1 æ’ä»¶è°ƒç”¨å·¥ä½œæµçš„å®Œæ•´æµç¨‹

ä»¥ `xxx.js` æ’ä»¶ä¸ºä¾‹ï¼Œå±•ç¤ºæ’ä»¶å¦‚ä½•è°ƒç”¨å·¥ä½œæµç³»ç»Ÿï¼š

**æ–‡ä»¶**: `core/plugin/example/xxx.js`

```javascript
import StreamLoader from '#infrastructure/aistream/loader.js';

export default class xxx extends plugin {
  constructor() {
    super({
      name: "XXXå·¥ä½œæµ",
      event: "message",
      priority: 1000,
      rule: [
        {
          reg: "^xxx",
          fnc: "triggerWorkflow",
          permission: 'master'
        }
      ]
    });
  }

  async triggerWorkflow() {
    const question = this.e.msg.trim().substring(3).trim();
    if (!question) {
      return this.reply('è¯·è¾“å…¥è¦è¯¢é—®çš„å†…å®¹');
    }

    // 1. è·å–å·¥ä½œæµå®ä¾‹
    const stream = StreamLoader.getStream('desktop');
    if (!stream) return this.reply('å·¥ä½œæµæœªåŠ è½½');

    // 2. è°ƒç”¨å·¥ä½œæµçš„processæ–¹æ³•
    await stream.process(this.e, question, {
      enableTodo: true,        // å¯ç”¨TODOå·¥ä½œæµ
      enableMemory: true,      // å¯ç”¨è®°å¿†ç³»ç»Ÿ
      enableDatabase: true     // å¯ç”¨çŸ¥è¯†åº“
    });

    return true;
  }
}
```

#### 3.2 æ’ä»¶è°ƒç”¨å·¥ä½œæµçš„æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Plugin as xxx.jsæ’ä»¶
    participant StreamLoader as StreamLoader
    participant Workflow as desktopå·¥ä½œæµ
    participant Python as PythonæœåŠ¡<br/>RAG/LLM
    
    User->>Plugin: å‘é€æ¶ˆæ¯<br/>"xxxæŸ¥è¯¢è‚¡ç¥¨"
    Plugin->>Plugin: è§„åˆ™åŒ¹é…<br/>reg: "^xxx"
    Plugin->>Plugin: æå–é—®é¢˜<br/>"æŸ¥è¯¢è‚¡ç¥¨"
    Plugin->>StreamLoader: getStream<br/>('desktop')
    StreamLoader-->>Plugin: è¿”å›å·¥ä½œæµå®ä¾‹
    Plugin->>Workflow: stream.process<br/>(e, question, options)
    
    Note over Workflow: å·¥ä½œæµå†…éƒ¨å¤„ç†
    Workflow->>Workflow: æ„å»ºç³»ç»Ÿæç¤ºè¯
    Workflow->>Workflow: åˆå¹¶è¾…åŠ©å·¥ä½œæµ<br/>memory/database/todo
    Workflow->>Workflow: æ„å»ºå‡½æ•°æç¤ºè¯
    Workflow->>Python: è°ƒç”¨LLM<br/>ç”Ÿæˆå›å¤
    Python-->>Workflow: è¿”å›AIå›å¤
    Workflow->>Workflow: è§£æå‡½æ•°è°ƒç”¨<br/>å¦‚[è‚¡ç¥¨:688270]
    Workflow->>Workflow: æ‰§è¡Œå‡½æ•°
    Workflow->>Python: è°ƒç”¨RAGæŸ¥è¯¢<br/>å¦‚éœ€è¦
    Python-->>Workflow: è¿”å›RAGç»“æœ
    Workflow->>User: å‘é€æœ€ç»ˆå›å¤
    
    Note over Plugin: å·¥ä½œæµå†…éƒ¨å·²å‘é€å›å¤<br/>æ’ä»¶æ— éœ€å†æ¬¡è°ƒç”¨reply()
```

#### 3.3 å…³é”®è¦ç‚¹

1. **æ’ä»¶è·å–å·¥ä½œæµ**ï¼šé€šè¿‡ `StreamLoader.getStream(name)` è·å–å·¥ä½œæµå®ä¾‹
2. **è°ƒç”¨processæ–¹æ³•**ï¼šä½¿ç”¨ `stream.process(e, question, options)` ç»Ÿä¸€æ¥å£
3. **è‡ªåŠ¨åˆå¹¶è¾…åŠ©å·¥ä½œæµ**ï¼šé€šè¿‡ `enableMemory`ã€`enableDatabase` ç­‰é€‰é¡¹è‡ªåŠ¨åˆå¹¶
4. **å›å¤æœºåˆ¶**ï¼šå·¥ä½œæµå†…éƒ¨å·²å¤„ç†å›å¤å‘é€ï¼Œæ’ä»¶æ— éœ€å†æ¬¡è°ƒç”¨ `reply()`
5. **é”™è¯¯å¤„ç†**ï¼šæ’ä»¶åº”æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å­˜åœ¨ï¼Œå¹¶æä¾›å‹å¥½çš„é”™è¯¯æç¤º

#### 3.4 æ’ä»¶è°ƒç”¨PythonæœåŠ¡çš„ç¤ºä¾‹

```javascript
// æ’ä»¶ç›´æ¥è°ƒç”¨PythonæœåŠ¡ï¼ˆä¸é€šè¿‡å·¥ä½œæµï¼‰
async queryRAG(e) {
  const result = await Bot.python.ragQuery(e.msg, {
    top_k: 5,
    collection: 'documents'
  });
  
  if (result.success) {
    await this.reply(`æŸ¥è¯¢ç»“æœï¼š${result.data.results[0].content}`);
  }
}
```

---

## è¿ç§»è®¡åˆ’

### é˜¶æ®µ1ï¼šåŸºç¡€è®¾æ–½æ­å»ºï¼ˆ1-2å‘¨ï¼‰

```mermaid
gantt
    title è¿ç§»è®¡åˆ’
    dateFormat  YYYY-MM-DD
    section åŸºç¡€è®¾æ–½
    PythonæœåŠ¡ç«¯æ¡†æ¶æ­å»º    :a1, 2026-01-15, 3d
    HTTPä»£ç†æ¥å£å®ç°        :a2, after a1, 2d
    Botå¯¹è±¡æ‰©å±•            :a3, after a1, 2d
    section RAGæœåŠ¡
    LangChainé›†æˆ          :b1, after a1, 5d
    ChromaDBé…ç½®           :b2, after b1, 2d
    RAG APIå®ç°            :b3, after b2, 3d
    section æµ‹è¯•
    å•å…ƒæµ‹è¯•               :c1, after b3, 3d
    é›†æˆæµ‹è¯•               :c2, after c1, 2d
```

### é˜¶æ®µ2ï¼šæ ¸å¿ƒåŠŸèƒ½è¿ç§»ï¼ˆ2-3å‘¨ï¼‰

- âœ… RAGåŠŸèƒ½è¿ç§»åˆ°Pythonç«¯
- âœ… LLMæœåŠ¡è¿ç§»åˆ°Pythonç«¯
- âœ… å‘é‡æ•°æ®åº“é›†æˆ
- âœ… æ–‡æ¡£å¤„ç†åŠŸèƒ½

### é˜¶æ®µ3ï¼šä¼˜åŒ–å’Œæ‰©å±•ï¼ˆæŒç»­ï¼‰

- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… ç¼“å­˜æœºåˆ¶
- âœ… ç›‘æ§å’Œæ—¥å¿—
- âœ… æ›´å¤šAIåŠŸèƒ½é›†æˆ

---

## é…ç½®ç¤ºä¾‹

### Node.jsé…ç½®

**æ–‡ä»¶**: `config/default_config/python.yaml`

```yaml
python:
  enabled: true
  url: "http://localhost:8000"  # æœ¬åœ°è°ƒç”¨ï¼Œä¸å¯¹å¤–æš´éœ²
  timeout: 5000                 # è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
  keep_alive: true              # ä¿æŒè¿æ¥ï¼Œå‡å°‘å»¶è¿Ÿ
  retry:
    max_attempts: 3
    delay: 500
  health_check:
    interval: 10000
    timeout: 2000
  connection_pool:
    max: 10                     # è¿æ¥æ± å¤§å°
    idle_timeout: 30000
```

### Pythoné…ç½®

**æ–‡ä»¶**: `subserver/pyserver/config.yaml`

```yaml
server:
  host: "127.0.0.1"    # ä»…æœ¬åœ°ç›‘å¬ï¼Œä¸å¯¹å¤–æš´éœ²
  port: 8000
  reload: false
  workers: 1           # å•è¿›ç¨‹ï¼Œå‡å°‘å¼€é”€

# æ¨¡å‹ç­–ç•¥ï¼šAPIä¼˜å…ˆï¼Œæœ¬åœ°ä¸ºè¾…
llm:
  provider: "api"  # api | ollama
  api_provider: "openai"  # openai | volcengine
  local_fallback: true  # APIä¸å¯ç”¨æ—¶é™çº§åˆ°æœ¬åœ°
  local_model: "llama3.2:7b"
  temperature: 0.7
  max_tokens: 2000

embedding:
  provider: "api"  # api | ollama
  api_provider: "openai"
  local_fallback: true
  local_model: "nomic-embed-text"

# å‘é‡å­˜å‚¨å’Œæ£€ç´¢ï¼ˆæ ¹æ®æ€§èƒ½è‡ªåŠ¨é€‰æ‹©ï¼‰
rag:
  vectorstore:
    type: "auto"  # auto | chroma | faiss
    persist_directory: "./data/chroma"
    collection_prefix: "xrk_"
  retrieval:
    top_k: "auto"  # æ ¹æ®æ€§èƒ½ç­‰çº§è‡ªåŠ¨è°ƒæ•´
  chunk_size: 1000
  chunk_overlap: 200

# æ€§èƒ½é€‚é…é…ç½®
performance:
  auto_detect: true
  device_tier: "auto"
  resource_monitor: true
  adaptive_degradation: true
```

---

## èµ„æºåˆ†é…ä¸æ€§èƒ½é€‚é…

### æ¨¡å‹ç­–ç•¥ï¼šAPIä¼˜å…ˆï¼Œæœ¬åœ°ä¸ºè¾…

**æ ¸å¿ƒåŸåˆ™**ï¼š
- âœ… **LLMæ¨¡å‹**ï¼šä¼˜å…ˆä½¿ç”¨APIï¼ˆOpenAIã€VolcEngineç­‰ï¼‰ï¼Œæœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰ä½œä¸ºé™çº§æ–¹æ¡ˆ
- âœ… **Embeddingæ¨¡å‹**ï¼šä¼˜å…ˆä½¿ç”¨APIï¼Œæœ¬åœ°æ¨¡å‹ä»…ç”¨äºçº¯æœ¬åœ°ç¯å¢ƒ
- âœ… **å‘é‡å­˜å‚¨**ï¼šæœ¬åœ°ChromaDB/FAISSï¼Œæ ¹æ®è®¾å¤‡æ€§èƒ½é€‰æ‹©
- âœ… **å‘é‡æ£€ç´¢**ï¼šæœ¬åœ°æ‰§è¡Œï¼Œæ ¹æ®æ•°æ®è§„æ¨¡é€‰æ‹©ChromaDBæˆ–FAISS

### èµ„æºåˆ†é…ç­–ç•¥

```mermaid
graph TB
    subgraph Detection["èµ„æºæ£€æµ‹"]
        A["æ£€æµ‹CPU<br/>å†…å­˜<br/>GPU"] --> B{"æ€§èƒ½è¯„ä¼°"}
        B -->|ä½ç«¯| C["Low Tier<br/><4GB RAM<br/>æ— GPU"]
        B -->|ä¸­ç«¯| D["Medium Tier<br/>4-16GB RAM<br/>å¯é€‰GPU"]
        B -->|é«˜ç«¯| E["High Tier<br/>>16GB RAM<br/>é«˜æ€§èƒ½GPU"]
    end
    
    subgraph Allocation["èµ„æºåˆ†é…"]
        C --> F["LLM: APIä¼˜å…ˆ<br/>Embedding: API<br/>å‘é‡: ChromaDB CPU<br/>æ£€ç´¢: top_k=3<br/>å¹¶å‘: 2"]
        D --> G["LLM: APIä¼˜å…ˆ<br/>Embedding: API<br/>å‘é‡: ChromaDB<br/>æ£€ç´¢: top_k=5<br/>å¹¶å‘: 5"]
        E --> H["LLM: APIä¼˜å…ˆ<br/>Embedding: API<br/>å‘é‡: FAISS GPU<br/>æ£€ç´¢: top_k=10<br/>å¹¶å‘: 10"]
    end
    
    subgraph Fallback["é™çº§ç­–ç•¥"]
        F --> I["APIä¸å¯ç”¨æ—¶<br/>é™çº§åˆ°æœ¬åœ°<br/>Ollama"]
        G --> I
        H --> I
    end
    
    style C fill:#ffebee
    style D fill:#fff3e0
    style E fill:#e8f5e9
    style I fill:#fff9c4
```

### æ€§èƒ½ç­‰çº§ä¸èµ„æºåˆ†é…

| æ€§èƒ½ç­‰çº§ | ç¡¬ä»¶ç‰¹å¾ | LLMæ¨¡å‹ | Embeddingæ¨¡å‹ | å‘é‡å­˜å‚¨ | æ£€ç´¢top_k | å¹¶å‘æ•° |
|---------|---------|---------|--------------|---------|----------|--------|
| **ä½ç«¯** | <4GB RAM, æ— GPU | APIä¼˜å…ˆ | APIä¼˜å…ˆ | ChromaDB CPU | 3 | 2 |
| **ä¸­ç«¯** | 4-16GB RAM, å¯é€‰GPU | APIä¼˜å…ˆ | APIä¼˜å…ˆ | ChromaDB | 5 | 5 |
| **é«˜ç«¯** | >16GB RAM, é«˜æ€§èƒ½GPU | APIä¼˜å…ˆ | APIä¼˜å…ˆ | FAISS GPU | 10 | 10 |

**è¯´æ˜**ï¼š
- **LLM/Embeddingæ¨¡å‹**ï¼šé»˜è®¤ä½¿ç”¨APIï¼Œä»…åœ¨APIä¸å¯ç”¨æˆ–é…ç½®ä¸ºçº¯æœ¬åœ°æ¨¡å¼æ—¶ä½¿ç”¨Ollama
- **å‘é‡å­˜å‚¨**ï¼šæœ¬åœ°ChromaDBï¼ˆè½»é‡ï¼‰æˆ–FAISSï¼ˆé«˜æ€§èƒ½ï¼‰ï¼Œæ ¹æ®è®¾å¤‡æ€§èƒ½é€‰æ‹©
- **å‘é‡æ£€ç´¢**ï¼šæœ¬åœ°æ‰§è¡Œï¼Œtop_kæ ¹æ®è®¾å¤‡æ€§èƒ½è°ƒæ•´

### èµ„æºåˆ†é…å®ç°

**æ–‡ä»¶**: `subserver/pyserver/core/performance_adapter.py`

```python
"""èµ„æºåˆ†é…é€‚é…å™¨"""
import psutil
from typing import Literal

DeviceTier = Literal["low", "medium", "high"]

class PerformanceAdapter:
    """èµ„æºåˆ†é…é€‚é…å™¨ - æ ¹æ®è®¾å¤‡æ€§èƒ½åˆ†é…å‘é‡å­˜å‚¨å’Œæ£€ç´¢èµ„æº"""
    
    def __init__(self):
        self.tier = self.detect_device_tier()
        self.config = self.get_tier_config()
    
    def detect_device_tier(self) -> DeviceTier:
        """è‡ªåŠ¨æ£€æµ‹è®¾å¤‡æ€§èƒ½ç­‰çº§"""
        memory_gb = psutil.virtual_memory().total / (1024**3)
        has_gpu = self._check_gpu()
        gpu_memory = self._get_gpu_memory() if has_gpu else 0
        
        if memory_gb < 4:
            return "low"
        elif memory_gb >= 16 and has_gpu and gpu_memory >= 8:
            return "high"
        else:
            return "medium"
    
    def get_tier_config(self) -> dict:
        """æ ¹æ®æ€§èƒ½ç­‰çº§è·å–èµ„æºåˆ†é…é…ç½®"""
        configs = {
            "low": {
                "llm_provider": "api",  # APIä¼˜å…ˆ
                "embedding_provider": "api",  # APIä¼˜å…ˆ
                "vectorstore": "chroma",  # ChromaDB CPUæ¨¡å¼
                "vectorstore_use_gpu": False,
                "retrieval_top_k": 3,  # å‡å°‘æ£€ç´¢æ•°é‡
                "max_concurrent": 2,
                "chunk_size": 500,
                "enable_local_fallback": True  # å…è®¸é™çº§åˆ°æœ¬åœ°
            },
            "medium": {
                "llm_provider": "api",
                "embedding_provider": "api",
                "vectorstore": "chroma",
                "vectorstore_use_gpu": False,
                "retrieval_top_k": 5,
                "max_concurrent": 5,
                "chunk_size": 1000,
                "enable_local_fallback": True
            },
            "high": {
                "llm_provider": "api",
                "embedding_provider": "api",
                "vectorstore": "faiss",  # FAISS GPUåŠ é€Ÿ
                "vectorstore_use_gpu": True,
                "retrieval_top_k": 10,
                "max_concurrent": 10,
                "chunk_size": 2000,
                "enable_local_fallback": True
            }
        }
        return configs.get(self.tier, configs["medium"])
    
    def _check_gpu(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰GPUï¼ˆç”¨äºå‘é‡æ£€ç´¢åŠ é€Ÿï¼‰"""
        try:
            import torch
            return torch.cuda.is_available()
        except:
            return False
    
    def _get_gpu_memory(self) -> float:
        """è·å–GPUæ˜¾å­˜ï¼ˆGBï¼‰"""
        try:
            import torch
            if torch.cuda.is_available():
                return torch.cuda.get_device_properties(0).total_memory / (1024**3)
        except:
            pass
        return 0
```

### èµ„æºç›‘æ§ä¸é™çº§ç­–ç•¥

**ç›‘æ§æŒ‡æ ‡**ï¼š
- å‘é‡å­˜å‚¨å†…å­˜ä½¿ç”¨ç‡
- å‘é‡æ£€ç´¢å“åº”æ—¶é—´
- APIè°ƒç”¨æˆåŠŸç‡
- æœ¬åœ°æ¨¡å‹èµ„æºå ç”¨ï¼ˆå¦‚å¯ç”¨ï¼‰

**é™çº§ç­–ç•¥**ï¼š
- APIä¸å¯ç”¨æ—¶ï¼Œè‡ªåŠ¨é™çº§åˆ°æœ¬åœ°Ollama
- å‘é‡å­˜å‚¨å†…å­˜ä¸è¶³æ—¶ï¼Œå‡å°‘æ£€ç´¢top_k
- æ£€ç´¢å“åº”æ—¶é—´è¿‡é•¿æ—¶ï¼Œåˆ‡æ¢åˆ°æ›´è½»é‡çš„å‘é‡å­˜å‚¨
- åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°ï¼Œé¿å…èµ„æºè€—å°½

**å®ç°ç¤ºä¾‹**ï¼š

```python
# subserver/pyserver/core/resource_monitor.py
class ResourceMonitor:
    """èµ„æºç›‘æ§å™¨ - ç›‘æ§å‘é‡å­˜å‚¨å’Œæ£€ç´¢èµ„æº"""
    
    def __init__(self, adapter: PerformanceAdapter):
        self.adapter = adapter
        self.memory_threshold = 85
        self.retrieval_timeout = 5000  # æ£€ç´¢è¶…æ—¶æ—¶é—´ï¼ˆmsï¼‰
    
    def check_and_degrade(self) -> bool:
        """æ£€æŸ¥èµ„æºå¹¶å†³å®šæ˜¯å¦é™çº§"""
        memory_usage = psutil.virtual_memory().percent
        
        # å†…å­˜ä¸è¶³æ—¶ï¼Œå‡å°‘æ£€ç´¢top_k
        if memory_usage > self.memory_threshold:
            if self.adapter.config["retrieval_top_k"] > 3:
                self.adapter.config["retrieval_top_k"] -= 2
                return True
        return False
    
    def should_use_local_fallback(self, api_available: bool) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨æœ¬åœ°é™çº§"""
        return not api_available and self.adapter.config["enable_local_fallback"]
```

### é…ç½®ç¤ºä¾‹

```yaml
# subserver/pyserver/config.yaml
# æ¨¡å‹ç­–ç•¥ï¼šAPIä¼˜å…ˆï¼Œæœ¬åœ°ä¸ºè¾…
llm:
  provider: "api"  # api | ollama
  api_provider: "openai"  # openai | volcengine | å…¶ä»–
  local_fallback: true  # APIä¸å¯ç”¨æ—¶é™çº§åˆ°æœ¬åœ°
  local_model: "llama3.2:7b"  # æœ¬åœ°é™çº§æ¨¡å‹

embedding:
  provider: "api"  # api | ollama
  api_provider: "openai"
  local_fallback: true
  local_model: "nomic-embed-text"

# å‘é‡å­˜å‚¨å’Œæ£€ç´¢ï¼ˆæ ¹æ®æ€§èƒ½è‡ªåŠ¨é€‰æ‹©ï¼‰
vectorstore:
  type: "auto"  # auto | chroma | faiss
  auto_detect: true
  chroma:
    persist_directory: "./data/chroma"
  faiss:
    use_gpu: true  # é«˜ç«¯è®¾å¤‡å¯ç”¨GPUåŠ é€Ÿ

retrieval:
  top_k: "auto"  # auto | 3 | 5 | 10ï¼ˆæ ¹æ®æ€§èƒ½ç­‰çº§ï¼‰
  timeout_ms: 5000

performance:
  device_tier: "auto"  # auto | low | medium | high
  resource_monitor: true
  adaptive_degradation: true
```

### å¥½å¤„ä¸æ”¹åŠ¨

**å¥½å¤„**ï¼š
- âœ… **APIä¼˜å…ˆ**ï¼šé»˜è®¤ä½¿ç”¨APIï¼Œæ€§èƒ½ç¨³å®šï¼Œæˆæœ¬å¯æ§
- âœ… **æœ¬åœ°é™çº§**ï¼šAPIä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§ï¼Œä¿è¯æœåŠ¡å¯ç”¨æ€§
- âœ… **èµ„æºä¼˜åŒ–**ï¼šå‘é‡å­˜å‚¨å’Œæ£€ç´¢æ ¹æ®è®¾å¤‡æ€§èƒ½è‡ªåŠ¨åˆ†é…
- âœ… **çµæ´»é€‚é…**ï¼šæ”¯æŒçº¯æœ¬åœ°ç¯å¢ƒï¼Œæ»¡è¶³éšç§å’Œå®‰å…¨éœ€æ±‚

**æ”¹åŠ¨è¯´æ˜**ï¼š
- æ¨¡å‹ç­–ç•¥ï¼šLLMå’ŒEmbeddingé»˜è®¤ä½¿ç”¨APIï¼Œæœ¬åœ°æ¨¡å‹ä½œä¸ºé™çº§æ–¹æ¡ˆ
- å‘é‡å­˜å‚¨ï¼šæ ¹æ®è®¾å¤‡æ€§èƒ½è‡ªåŠ¨é€‰æ‹©ChromaDBæˆ–FAISS
- æ£€ç´¢ä¼˜åŒ–ï¼šæ ¹æ®è®¾å¤‡æ€§èƒ½åŠ¨æ€è°ƒæ•´top_kå’Œå¹¶å‘æ•°
- èµ„æºç›‘æ§ï¼šé‡ç‚¹ç›‘æ§å‘é‡å­˜å‚¨å†…å­˜å’Œæ£€ç´¢æ€§èƒ½

---

## ä¼˜åŠ¿æ€»ç»“

### 1. æ€§èƒ½ä¼˜åŒ–

- âœ… **æœ¬åœ°è°ƒç”¨**ï¼šPythonæœåŠ¡è¿è¡Œåœ¨æœ¬åœ°ï¼Œç½‘ç»œå»¶è¿Ÿæä½
- âœ… **è¿æ¥æ± **ï¼šHTTPè¿æ¥å¤ç”¨ï¼Œå‡å°‘è¿æ¥å»ºç«‹å¼€é”€
- âœ… **å¼‚æ­¥å¤„ç†**ï¼šPythonå¼‚æ­¥æ¡†æ¶æ€§èƒ½ä¼˜å¼‚
- âœ… **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡è¯·æ±‚ï¼Œæå‡ååé‡
- âœ… **APIä¼˜å…ˆ**ï¼šé»˜è®¤ä½¿ç”¨APIï¼Œæ€§èƒ½ç¨³å®šï¼›æœ¬åœ°æ¨¡å‹ä½œä¸ºé™çº§æ–¹æ¡ˆ

### 2. ç”Ÿæ€ä¼˜åŠ¿

- âœ… **æˆç†Ÿå·¥å…·**ï¼šLangChainã€LlamaIndexç­‰æˆç†Ÿæ¡†æ¶
- âœ… **ä¸°å¯Œæ¨¡å‹**ï¼šæ”¯æŒå„ç§å¼€æºå’Œå•†ä¸šæ¨¡å‹
- âœ… **å‘é‡æ•°æ®åº“**ï¼šChromaDBæŒä¹…åŒ–å­˜å‚¨ï¼Œæ€§èƒ½ä¼˜å¼‚

### 3. è®¾å¤‡æ€§èƒ½é€‚é…

- âœ… **è‡ªåŠ¨æ£€æµ‹**ï¼šå¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹CPU/å†…å­˜/GPUï¼Œç¡®å®šæ€§èƒ½ç­‰çº§
- âœ… **åˆ†çº§é…ç½®**ï¼šä½ç«¯/ä¸­ç«¯/é«˜ç«¯ä¸‰æ¡£é…ç½®ï¼Œè‡ªåŠ¨é€‚é…
- âœ… **èµ„æºç›‘æ§**ï¼šå®æ—¶ç›‘æ§èµ„æºä½¿ç”¨ç‡ï¼Œå¿…è¦æ—¶è‡ªåŠ¨é™çº§
- âœ… **çµæ´»éƒ¨ç½²**ï¼šæ”¯æŒä»ä½ç«¯åˆ°é«˜ç«¯çš„å„ç§è®¾å¤‡ï¼Œå¹¿æ³›å…¼å®¹

### 4. æç¤ºè¯ä¼˜åŒ–

- âœ… **æ¨¡æ¿åŒ–**ï¼šä½¿ç”¨LangChain PromptTemplateï¼Œå‡å°‘é‡å¤æ„å»º
- âœ… **å‹ç¼©**ï¼šPromptCompressorå‹ç¼©é•¿æç¤ºè¯ï¼Œå‡å°‘30-50% tokenæ¶ˆè€—
- âœ… **ç¼“å­˜**ï¼šæç¤ºè¯ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤è®¡ç®—
- âœ… **åˆ†å±‚æ„å»º**ï¼šç³»ç»Ÿ/å‡½æ•°/ä¸Šä¸‹æ–‡åˆ†å±‚ï¼ŒæŒ‰éœ€ç”Ÿæˆ

### 5. å¼€å‘ä½“éªŒ

- âœ… **ç»Ÿä¸€æ¥å£**ï¼šBotå¯¹è±¡ç»Ÿä¸€è°ƒç”¨ï¼Œæ’ä»¶å¼€å‘ç®€å•
- âœ… **ç±»å‹å®‰å…¨**ï¼šPydanticæä¾›ç±»å‹éªŒè¯
- âœ… **æ˜“äºæ‰©å±•**ï¼šFastAPIè·¯ç”±ç³»ç»Ÿçµæ´»

### 6. å®‰å…¨æ€§

- âœ… **å†…éƒ¨æœåŠ¡**ï¼šPythonæœåŠ¡ä»…ç›‘å¬æœ¬åœ°ï¼Œä¸å¯¹å¤–æš´éœ²
- âœ… **æƒé™æ§åˆ¶**ï¼šæ‰€æœ‰è°ƒç”¨ç»è¿‡Node.jsä¸»æœåŠ¡ç«¯éªŒè¯
- âœ… **éš”ç¦»éƒ¨ç½²**ï¼šPythonæœåŠ¡ç‹¬ç«‹è¿è¡Œï¼Œæ•…éšœéš”ç¦»

---

## ä»£ç æ¸…ç†å’Œè¿ç§»è§„åˆ’

### ğŸ—‘ï¸ å¯åˆ é™¤çš„Node.jsç«¯ä»£ç 

#### 1. Embeddingç›¸å…³ä»£ç ï¼ˆè¿ç§»åˆ°LangChainï¼‰

**ä½ç½®**: `src/infrastructure/aistream/aistream.js`

**å¯åˆ é™¤çš„æ–¹æ³•**ï¼š
- âŒ `initLightweightEmbedding()` - BM25ç®—æ³•ï¼ˆLangChainæœ‰æ›´å¥½çš„ï¼‰
- âŒ `generateEmbedding()` - Embeddingç”Ÿæˆï¼ˆLangChainå¤„ç†ï¼‰
- âŒ `generateRemoteEmbedding()` - è¿œç¨‹Embedding APIï¼ˆLangChainå¤„ç†ï¼‰
- âŒ `cosineSimilarity()` - å‘é‡ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆLangChainå¤„ç†ï¼‰
- âŒ `retrieveContexts()` - ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆLangChain RAGå¤„ç†ï¼‰
- âŒ `storeMessageWithEmbedding()` - æ¶ˆæ¯å­˜å‚¨ï¼ˆLangChainå‘é‡æ•°æ®åº“å¤„ç†ï¼‰

**ä¿ç•™**ï¼š
- âœ… `initEmbedding()` - ä¿ç•™æ¥å£ï¼Œä½†æ”¹ä¸ºè°ƒç”¨PythonæœåŠ¡
- âœ… `embeddingConfig` - ä¿ç•™é…ç½®ï¼Œä½†æ”¹ä¸ºæŒ‡å‘PythonæœåŠ¡

#### 2. çŸ¥è¯†åº“å‘é‡æ£€ç´¢ï¼ˆè¿ç§»åˆ°LangChainï¼‰

**ä½ç½®**: `core/stream/database.js`

**å¯åˆ é™¤çš„æ–¹æ³•**ï¼š
- âŒ `queryKnowledgeWithEmbedding()` - å‘é‡æ£€ç´¢ï¼ˆLangChainå¤„ç†ï¼‰
- âŒ `generateEmbeddingAsync()` - Embeddingç”Ÿæˆï¼ˆLangChainå¤„ç†ï¼‰
- âŒ `saveEmbeddingAsync()` - Embeddingä¿å­˜ï¼ˆLangChainå‘é‡æ•°æ®åº“å¤„ç†ï¼‰
- âŒ `retrieveKnowledgeContexts()` - çŸ¥è¯†æ£€ç´¢ï¼ˆLangChain RAGå¤„ç†ï¼‰

**ä¿ç•™**ï¼š
- âœ… `saveKnowledge()` - ä¿ç•™ï¼Œä½†æ”¹ä¸ºè°ƒç”¨PythonæœåŠ¡ç´¢å¼•
- âœ… `queryKnowledge()` - ä¿ç•™æ¥å£ï¼Œä½†æ”¹ä¸ºè°ƒç”¨Python RAGæœåŠ¡
- âœ… `listDatabases()` - ä¿ç•™ï¼Œä¸šåŠ¡é€»è¾‘

#### 3. è®°å¿†ç³»ç»Ÿå‘é‡æ£€ç´¢ï¼ˆè¿ç§»åˆ°LangChainï¼‰

**ä½ç½®**: `core/stream/memory.js`

**å¯åˆ é™¤çš„æ–¹æ³•**ï¼š
- âŒ æ‰€æœ‰å‘é‡æ£€ç´¢ç›¸å…³ä»£ç ï¼ˆè¿ç§»åˆ°LangChainï¼‰

**ä¿ç•™**ï¼š
- âœ… è®°å¿†å­˜å‚¨å’ŒæŸ¥è¯¢æ¥å£ï¼ˆæ”¹ä¸ºè°ƒç”¨PythonæœåŠ¡ï¼‰

#### 4. BM25ç®—æ³•å®ç°ï¼ˆå®Œå…¨åˆ é™¤ï¼‰

**ä½ç½®**: `src/infrastructure/aistream/aistream.js`

**å¯åˆ é™¤**ï¼š
- âŒ `SimilarityCalculator` ç±»ï¼ˆBM25ç®—æ³•ï¼‰
- âŒ æ‰€æœ‰BM25ç›¸å…³ä»£ç 

**åŸå› **ï¼šLangChainçš„å‘é‡æ£€ç´¢æ¯”BM25æ•ˆæœå¥½å¾—å¤š

---

### ğŸ”„ è¿ç§»åˆ°Pythonç«¯çš„ä»£ç 

#### 1. RAGåŠŸèƒ½ â†’ LangChain

```python
# è¿ç§»å‰ï¼ˆNode.jsï¼‰
# core/stream/database.js
async queryKnowledgeWithEmbedding(records, query) {
  // å‘é‡æ£€ç´¢é€»è¾‘
  const queryEmbedding = await this.generateEmbedding(query);
  // ... ç›¸ä¼¼åº¦è®¡ç®—
}

# è¿ç§»åï¼ˆPython + LangChainï¼‰
# subserver/pyserver/core/rag_service.py
from langchain.chains import RetrievalQA
from langchain.vectorstores import Chroma

class RAGService:
    async def query(self, query: str):
        # LangChainå¤„ç†RAGæŸ¥è¯¢
        result = self.qa_chain.invoke({"query": query})
        return result
```

#### 2. Embeddingç”Ÿæˆ â†’ LangChain

```python
# è¿ç§»å‰ï¼ˆNode.jsï¼‰
# src/infrastructure/aistream/aistream.js
async generateEmbedding(text) {
  // è°ƒç”¨APIæˆ–BM25
}

# è¿ç§»åï¼ˆPython + LangChainï¼‰
# subserver/pyserver/core/rag_service.py
from langchain_community.embeddings import OllamaEmbeddings

embeddings = OllamaEmbeddings(model="nomic-embed-text")
vector = embeddings.embed_query(text)
```

#### 3. å‘é‡æ•°æ®åº“ â†’ ChromaDB/FAISS

```python
# è¿ç§»å‰ï¼ˆNode.jsï¼‰
# ä½¿ç”¨Rediså­˜å‚¨å‘é‡ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰

# è¿ç§»åï¼ˆPython + LangChainï¼‰
# subserver/pyserver/core/rag_service.py
from langchain.vectorstores import Chroma

vectorstore = Chroma(
    collection_name="documents",
    embedding_function=embeddings,
    persist_directory="./data/chroma"
)
```

---

### ğŸ“‹ è¯¦ç»†åˆ é™¤æ¸…å•

#### æ–‡ä»¶çº§åˆ«åˆ é™¤

| æ–‡ä»¶/æ¨¡å— | åˆ é™¤å†…å®¹ | è¿ç§»åˆ° | ä¼˜å…ˆçº§ |
|-----------|---------|--------|--------|
| `src/infrastructure/aistream/aistream.js` | BM25ç®—æ³•ã€Embeddingç”Ÿæˆ | LangChain | ğŸ”´ é«˜ |
| `core/stream/database.js` | å‘é‡æ£€ç´¢é€»è¾‘ | LangChain RAG | ğŸ”´ é«˜ |
| `core/stream/memory.js` | å‘é‡æ£€ç´¢é€»è¾‘ | LangChain RAG | ğŸ”´ é«˜ |
| `src/infrastructure/aistream/aistream.js` | `retrieveContexts()` | LangChain RAG | ğŸ”´ é«˜ |

#### æ–¹æ³•çº§åˆ«åˆ é™¤

**`src/infrastructure/aistream/aistream.js`**ï¼š
- âŒ `initLightweightEmbedding()` (~50è¡Œ)
- âŒ `generateEmbedding()` (~30è¡Œ)
- âŒ `generateRemoteEmbedding()` (~30è¡Œ)
- âŒ `cosineSimilarity()` (~20è¡Œ)
- âŒ `retrieveContexts()` (~100è¡Œ)
- âŒ `storeMessageWithEmbedding()` (~50è¡Œ)
- âŒ `SimilarityCalculator` ç±» (~200è¡Œ)

**`core/stream/database.js`**ï¼š
- âŒ `queryKnowledgeWithEmbedding()` (~50è¡Œ)
- âŒ `generateEmbeddingAsync()` (~20è¡Œ)
- âŒ `saveEmbeddingAsync()` (~30è¡Œ)
- âŒ `retrieveKnowledgeContexts()` (~40è¡Œ)

**æ€»è®¡å¯åˆ é™¤**ï¼š~620è¡Œä»£ç 

#### 4. é…ç½®é¡¹æ¸…ç†

**ä½ç½®**: `config/default_config/aistream.yaml`

**å¯åˆ é™¤çš„é…ç½®**ï¼š
- âŒ `embedding.mode: local` - BM25æ¨¡å¼ï¼ˆä¸å†éœ€è¦ï¼‰
- âŒ `embedding.remote.apiUrl` - è¿œç¨‹Embedding APIï¼ˆLangChainå¤„ç†ï¼‰
- âŒ `embedding.remote.apiKey` - APIå¯†é’¥ï¼ˆLangChainå¤„ç†ï¼‰

**ä¿ç•™çš„é…ç½®**ï¼š
- âœ… `embedding.enabled` - ä¿ç•™ï¼Œä½†æ”¹ä¸ºæŒ‡å‘PythonæœåŠ¡
- âœ… å·¥ä½œæµç›¸å…³é…ç½®
- âœ… æ’ä»¶ç›¸å…³é…ç½®

---

### ğŸ”„ è¿ç§»æ˜ å°„è¡¨

| Node.jsç«¯åŠŸèƒ½ | è¿ç§»åˆ° | Pythonç«¯å®ç° |
|--------------|--------|-------------|
| `generateEmbedding()` | LangChain | `OllamaEmbeddings.embed_query()` |
| `queryKnowledgeWithEmbedding()` | LangChain RAG | `RetrievalQA.invoke()` |
| `retrieveContexts()` | LangChain RAG | `vectorstore.similarity_search()` |
| `cosineSimilarity()` | LangChain | `vectorstore.similarity_search()` |
| BM25ç®—æ³• | LangChain | å‘é‡æ£€ç´¢ï¼ˆæ•ˆæœæ›´å¥½ï¼‰ |
| Rediså‘é‡å­˜å‚¨ | ChromaDB | `Chroma(vectorstore)` |
| æ–‡æ¡£åŠ è½½/åˆ†å‰² | LangChain | `TextLoader` + `RecursiveCharacterTextSplitter` |

---

### ğŸ“ è¿ç§»æ­¥éª¤æ¦‚è§ˆ

1. **æ­å»ºPythonæœåŠ¡ç«¯**ï¼šå®‰è£…ä¾èµ–ï¼Œåˆ›å»ºAPIç›®å½•ç»“æ„
2. **å®ç°LangChain RAGæœåŠ¡**ï¼šä½¿ç”¨LangChainæ›¿ä»£Node.jsç«¯å‘é‡æ£€ç´¢
3. **æ›´æ–°Node.jsç«¯è°ƒç”¨**ï¼šå°†`queryKnowledge`ç­‰æ–¹æ³•æ”¹ä¸ºè°ƒç”¨PythonæœåŠ¡
4. **åˆ é™¤å†—ä½™ä»£ç **ï¼šåˆ é™¤Embeddingã€BM25ã€å‘é‡æ£€ç´¢ç›¸å…³ä»£ç 
5. **æ›´æ–°é…ç½®**ï¼šä¿®æ”¹é…ç½®æŒ‡å‘PythonæœåŠ¡

---

### âš ï¸ é‡è¦è¯´æ˜

1. **Pythonå­æœåŠ¡ç«¯å®šä½**
   - PythonæœåŠ¡ä½œä¸ºå†…éƒ¨å­æœåŠ¡ï¼Œä»…é¢å‘Node.jsä¸»æœåŠ¡ç«¯è°ƒç”¨
   - ä¸å¯¹å¤–æš´éœ²HTTPæ¥å£ï¼Œç¡®ä¿å®‰å…¨æ€§
   - æœ¬åœ°è°ƒç”¨ï¼ˆlocalhostï¼‰ï¼Œä¸“æ³¨ä¼˜åŒ–å»¶è¿Ÿå®ç°0å»¶è¿Ÿå“åº”
   - é€šè¿‡è¿æ¥æ± ã€è¯·æ±‚ç¼“å­˜ç­‰æŠ€æœ¯ä¼˜åŒ–æ€§èƒ½

2. **é”™è¯¯å¤„ç†**
   - PythonæœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œéœ€è¦æœ‰é™çº§æ–¹æ¡ˆ
   - æ·»åŠ å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨é‡è¿æœºåˆ¶
   - æœåŠ¡å¯åŠ¨å¤±è´¥æ—¶ï¼ŒNode.jsç«¯åº”ä¼˜é›…é™çº§

3. **æ•°æ®è¿ç§»**
   - ç°æœ‰Redisä¸­çš„å‘é‡æ•°æ®éœ€è¦è¿ç§»åˆ°ChromaDB
   - æä¾›æ•°æ®è¿ç§»è„šæœ¬ï¼Œæ”¯æŒå¢é‡è¿ç§»
   - è¿ç§»æœŸé—´ä¿è¯æœåŠ¡å¯ç”¨æ€§

4. **æ€§èƒ½ä¼˜åŒ–**
   - æœ¬åœ°HTTPè°ƒç”¨ä½¿ç”¨keep-aliveè¿æ¥
   - å®ç°è¯·æ±‚ç¼“å­˜æœºåˆ¶ï¼Œå‡å°‘é‡å¤è°ƒç”¨
   - å¼‚æ­¥æ‰¹é‡å¤„ç†ï¼Œæå‡ååé‡

---

### âœ… ä¿ç•™çš„Node.jsç«¯ä»£ç 

#### 1. å·¥ä½œæµç³»ç»Ÿï¼ˆå¿…é¡»ä¿ç•™ï¼‰

**ä½ç½®**: `src/utils/workflow-manager.js`

**ä¿ç•™åŸå› **ï¼š
- âœ… ä¸šåŠ¡é€»è¾‘å±‚ä»»åŠ¡è§„åˆ’
- âœ… çŠ¶æ€ç®¡ç†å’ŒæŒä¹…åŒ–
- âœ… å¤šå¹³å°é›†æˆï¼ˆQQç­‰ï¼‰
- âœ… é”™è¯¯å¤„ç†å’Œé‡è¯•

**ä½†éœ€è¦ä¿®æ”¹**ï¼š
- ğŸ”„ å·¥ä½œæµæ­¥éª¤å¯ä»¥è°ƒç”¨LangChain Agent

#### 2. æ’ä»¶ç³»ç»Ÿï¼ˆå¿…é¡»ä¿ç•™ï¼‰

**ä½ç½®**: `src/infrastructure/plugins/`

**ä¿ç•™åŸå› **ï¼š
- âœ… åŠŸèƒ½æ¨¡å—åŒ–
- âœ… ç”Ÿå‘½å‘¨æœŸç®¡ç†
- âœ… æƒé™éªŒè¯

#### 3. äº‹ä»¶ç³»ç»Ÿï¼ˆå¿…é¡»ä¿ç•™ï¼‰

**ä½ç½®**: `src/infrastructure/listener/`

**ä¿ç•™åŸå› **ï¼š
- âœ… äº‹ä»¶é©±åŠ¨æ¶æ„
- âœ… å¤šå¹³å°äº‹ä»¶å¤„ç†

#### 4. å·¥å…·æ³¨å†Œå’Œè°ƒç”¨ï¼ˆä¿ç•™ä½†ç®€åŒ–ï¼‰

**ä½ç½®**: `src/infrastructure/aistream/loader.js`

**ä¿ç•™åŸå› **ï¼š
- âœ… å·¥å…·æ³¨å†Œæœºåˆ¶
- âœ… å‡½æ•°è°ƒç”¨æ¡†æ¶

**ä½†éœ€è¦ä¿®æ”¹**ï¼š
- ğŸ”„ éƒ¨åˆ†å·¥å…·å¯ä»¥è°ƒç”¨LangChain Agent

---

### ğŸ”„ è¿ç§»åçš„æ¶æ„

```mermaid
graph TB
    subgraph NodeJS2["Node.jsä¸»æœåŠ¡ç«¯<br/>ç²¾ç®€å"]
        A["å·¥ä½œæµç³»ç»Ÿ"] --> E["PythonæœåŠ¡<br/>ä»£ç†"]
        B["æ’ä»¶ç³»ç»Ÿ"] --> E
        C["äº‹ä»¶ç³»ç»Ÿ"] --> A
        C --> B
        E --> F["HTTPå®¢æˆ·ç«¯<br/>æœ¬åœ°è°ƒç”¨"]
    end
    
    subgraph Python2["Pythonå­æœåŠ¡ç«¯<br/>å†…éƒ¨æœåŠ¡<br/>ä¸å¯¹å¤–æš´éœ²"]
        F --> G["FastAPIè·¯ç”±"]
        G --> H["RAGæœåŠ¡"]
        G --> I["LLMæœåŠ¡"]
        G --> J["å‘é‡æ•°æ®åº“"]
        
        H --> K["LangChain<br/>RAG"]
        H --> L["ChromaDB"]
        I --> M["APIä¼˜å…ˆ<br/>æœ¬åœ°é™çº§"]
        J --> L
    end
    
    style A fill:#fff4e1
    style B fill:#fff4e1
    style E fill:#fff4e1
    style H fill:#e8f5e9
    style I fill:#e8f5e9
    style J fill:#e8f5e9
```

---

### ğŸ“… è¿ç§»æ—¶é—´è¡¨

#### é˜¶æ®µ1ï¼šPythonæœåŠ¡ç«¯æ­å»ºï¼ˆ1å‘¨ï¼‰

```mermaid
gantt
    title è¿ç§»æ—¶é—´è¡¨
    dateFormat  YYYY-MM-DD
    section é˜¶æ®µ1ï¼šåŸºç¡€è®¾æ–½
    FastAPIæ¡†æ¶æ­å»º        :a1, 2026-01-15, 2d
    HTTPä»£ç†æ¥å£å®ç°       :a2, after a1, 1d
    Botå¯¹è±¡æ‰©å±•           :a3, after a1, 1d
    section é˜¶æ®µ2ï¼šLangChainé›†æˆ
    LangChain RAGæœåŠ¡     :b1, after a1, 3d
    LangChain Agent       :b2, after b1, 2d
    ChromaDBé…ç½®          :b3, after b1, 1d
    section é˜¶æ®µ3ï¼šä»£ç æ¸…ç†
    åˆ é™¤Embeddingä»£ç      :c1, after b1, 1d
    åˆ é™¤å‘é‡æ£€ç´¢ä»£ç       :c2, after b1, 1d
    æ›´æ–°è°ƒç”¨æ¥å£          :c3, after c1, 1d
    section é˜¶æ®µ4ï¼šæµ‹è¯•
    å•å…ƒæµ‹è¯•              :d1, after c3, 2d
    é›†æˆæµ‹è¯•              :d2, after d1, 1d
```

#### é˜¶æ®µ2ï¼šåŠŸèƒ½è¿ç§»ï¼ˆ2å‘¨ï¼‰

- âœ… RAGåŠŸèƒ½è¿ç§»åˆ°LangChain
- âœ… Embeddingç”Ÿæˆè¿ç§»åˆ°LangChain
- âœ… å‘é‡æ•°æ®åº“è¿ç§»åˆ°ChromaDB
- âœ… æ–‡æ¡£å¤„ç†è¿ç§»åˆ°LangChain
- âœ… æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½å®ç°
- âœ… è®¾å¤‡æ€§èƒ½é€‚é…ç³»ç»Ÿå®ç°
- âœ… è®¾å¤‡æ€§èƒ½é€‚é…ç³»ç»Ÿå®ç°

#### é˜¶æ®µ3ï¼šä»£ç æ¸…ç†ï¼ˆ1å‘¨ï¼‰

- âœ… åˆ é™¤Node.jsç«¯çš„Embeddingä»£ç 
- âœ… åˆ é™¤BM25ç®—æ³•å®ç°
- âœ… åˆ é™¤å‘é‡æ£€ç´¢é€»è¾‘
- âœ… æ›´æ–°è°ƒç”¨æ¥å£

#### é˜¶æ®µ4ï¼šæµ‹è¯•å’Œä¼˜åŒ–ï¼ˆ1å‘¨ï¼‰

- âœ… åŠŸèƒ½æµ‹è¯•
- âœ… æ€§èƒ½æµ‹è¯•ï¼ˆåŒ…æ‹¬æç¤ºè¯ä¼˜åŒ–æ•ˆæœï¼‰
- âœ… æ–‡æ¡£æ›´æ–°

---

### ğŸ¯ è¿ç§»åçš„ä»£ç ç»“æ„

#### Node.jsç«¯ï¼ˆç²¾ç®€åï¼‰

```
src/
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ aistream/
â”‚   â”‚   â””â”€â”€ aistream.js          # ç²¾ç®€ï¼šåªä¿ç•™å·¥ä½œæµã€æ’ä»¶æ¡†æ¶
â”‚   â””â”€â”€ plugins/                 # ä¿ç•™ï¼šæ’ä»¶ç³»ç»Ÿ
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ python-client.js         # æ–°å¢ï¼šPythonæœåŠ¡å®¢æˆ·ç«¯
â””â”€â”€ bot.js                       # ä¿ç•™ï¼šBotä¸»ç±»

core/
â”œâ”€â”€ workflow-manager.js          # ä¿ç•™ï¼šå·¥ä½œæµç³»ç»Ÿ
â”œâ”€â”€ stream/
â”‚   â”œâ”€â”€ desktop.js              # ä¿ç•™ï¼šæ¡Œé¢å·¥å…·
â”‚   â”œâ”€â”€ tools.js                # ä¿ç•™ï¼šåŸºç¡€å·¥å…·
â”‚   â”œâ”€â”€ database.js             # ç²¾ç®€ï¼šåªä¿ç•™æ¥å£ï¼Œè°ƒç”¨Python
â”‚   â””â”€â”€ memory.js               # ç²¾ç®€ï¼šåªä¿ç•™æ¥å£ï¼Œè°ƒç”¨Python
â””â”€â”€ http/
    â””â”€â”€ python.js               # æ–°å¢ï¼šPythonæœåŠ¡ä»£ç†
```

#### Pythonç«¯ï¼ˆæ–°å¢ï¼‰

```
subserver/pyserver/
â”œâ”€â”€ apis/
â”‚   â”œâ”€â”€ rag_api.py              # æ–°å¢ï¼šRAGæœåŠ¡API
â”‚   â”œâ”€â”€ llm_api.py              # æ–°å¢ï¼šLLMæœåŠ¡API
â”‚   â”œâ”€â”€ prompt_api.py           # æç¤ºè¯ä¼˜åŒ–API
â”‚   â””â”€â”€ document_api.py         # æ–‡æ¡£å¤„ç†API
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ rag_service.py          # RAGæœåŠ¡ï¼ˆLangChainï¼‰
â”‚   â”œâ”€â”€ llm_service.py          # LLMæœåŠ¡ï¼ˆLangChainï¼‰
â”‚   â”œâ”€â”€ prompt_optimizer.py     # æç¤ºè¯ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ performance_adapter.py  # æ€§èƒ½é€‚é…å™¨
â”‚   â”œâ”€â”€ resource_monitor.py     # èµ„æºç›‘æ§å™¨
â”‚   â””â”€â”€ document_service.py     # æ–‡æ¡£å¤„ç†ï¼ˆLangChainï¼‰
â””â”€â”€ main.py                     # FastAPIåº”ç”¨
```

---

### ğŸ“Š ä»£ç é‡å˜åŒ–

| é¡¹ç›® | è¿ç§»å‰ | è¿ç§»å | å˜åŒ– |
|------|--------|--------|------|
| **Node.jsç«¯** | ~15,000è¡Œ | ~12,000è¡Œ | **-3,000è¡Œï¼ˆ-20%ï¼‰** |
| **Pythonç«¯** | ~500è¡Œ | ~3,500è¡Œ | **+3,000è¡Œï¼ˆæ–°å¢ï¼‰** |
| **æ€»è®¡** | ~15,500è¡Œ | ~15,500è¡Œ | **æŒå¹³** |

**ä¼˜åŠ¿**ï¼š
- âœ… Node.jsç«¯ä»£ç ç²¾ç®€ï¼ŒèŒè´£æ¸…æ™°
- âœ… Pythonç«¯åŠŸèƒ½å¼ºå¤§ï¼ŒåŒ…å«æç¤ºè¯ä¼˜åŒ–
- âœ… æ€»ä½“ä»£ç é‡æŒå¹³ï¼Œä½†åŠŸèƒ½æ›´å¼ºå¤§

---

## ğŸ“‹ åˆ é™¤å’Œä¿ç•™æ€»ç»“

### âŒ å¿…é¡»åˆ é™¤çš„ä»£ç ï¼ˆè¿ç§»åˆ°LangChainï¼‰

| æ¨¡å— | ä»£ç ä½ç½® | åˆ é™¤å†…å®¹ | æ›¿ä»£æ–¹æ¡ˆ |
|------|---------|---------|---------|
| **Embeddingç”Ÿæˆ** | `src/infrastructure/aistream/aistream.js` | `generateEmbedding()`, `generateRemoteEmbedding()` | LangChain `OllamaEmbeddings` |
| **BM25ç®—æ³•** | `src/infrastructure/aistream/aistream.js` | `SimilarityCalculator`ç±» | LangChainå‘é‡æ£€ç´¢ |
| **å‘é‡æ£€ç´¢** | `core/stream/database.js` | `queryKnowledgeWithEmbedding()` | LangChain RAG |
| **å‘é‡å­˜å‚¨** | Redisä¸´æ—¶æ–¹æ¡ˆ | Rediså‘é‡å­˜å‚¨ | ChromaDB |
| **æ–‡æ¡£å¤„ç†** | Node.jsåŸºç¡€å®ç° | æ–‡æ¡£åŠ è½½/åˆ†å‰² | LangChainæ–‡æ¡£å¤„ç† |

### âœ… å¿…é¡»ä¿ç•™çš„ä»£ç ï¼ˆä¸šåŠ¡é€»è¾‘å±‚ï¼‰

| æ¨¡å— | ä»£ç ä½ç½® | ä¿ç•™åŸå›  |
|------|---------|---------|
| **å·¥ä½œæµç³»ç»Ÿ** | `core/workflow-manager.js` | ä¸šåŠ¡é€»è¾‘è§„åˆ’ã€çŠ¶æ€ç®¡ç† |
| **æ’ä»¶ç³»ç»Ÿ** | `src/infrastructure/plugins/` | åŠŸèƒ½æ¨¡å—åŒ–ã€ç”Ÿå‘½å‘¨æœŸç®¡ç† |
| **äº‹ä»¶ç³»ç»Ÿ** | `src/infrastructure/listener/` | äº‹ä»¶é©±åŠ¨æ¶æ„ |
| **å·¥å…·æ³¨å†Œ** | `src/infrastructure/aistream/loader.js` | å·¥å…·æ³¨å†Œæœºåˆ¶ |
| **å¤šå¹³å°é€‚é…** | `core/tasker/` | QQç­‰å¹³å°é›†æˆ |

### ğŸ”„ éœ€è¦ä¿®æ”¹çš„ä»£ç ï¼ˆæ”¹ä¸ºè°ƒç”¨PythonæœåŠ¡ï¼‰

| æ¨¡å— | ä¿®æ”¹å†…å®¹ | æ–°å®ç° |
|------|---------|--------|
| **çŸ¥è¯†åº“æŸ¥è¯¢** | `core/stream/database.js` | æ”¹ä¸ºè°ƒç”¨`Bot.python.ragQuery()` |
| **è®°å¿†æŸ¥è¯¢** | `core/stream/memory.js` | æ”¹ä¸ºè°ƒç”¨`Bot.python.ragQuery()` |
| **ä¸Šä¸‹æ–‡æ£€ç´¢** | `src/infrastructure/aistream/aistream.js` | æ”¹ä¸ºè°ƒç”¨`Bot.python.ragQuery()` |

---

## ğŸ¯ è¿ç§»ä¼˜å…ˆçº§

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³æ‰§è¡Œï¼‰

1. **æ­å»ºPythonæœåŠ¡ç«¯æ¡†æ¶**
   - FastAPIåº”ç”¨
   - HTTPè·¯ç”±
   - é…ç½®ç®¡ç†

2. **å®ç°LangChain RAGæœåŠ¡**
   - RAGæœåŠ¡å®ç°
   - ChromaDBé…ç½®
   - APIæ¥å£

3. **å®ç°HTTPä»£ç†æ¥å£**
   - Node.jsç«¯Pythonä»£ç†
   - Botå¯¹è±¡æ‰©å±•

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆ1-2å‘¨å†…ï¼‰

4. **è¿ç§»çŸ¥è¯†åº“åŠŸèƒ½**
   - æ›´æ–°`database.js`è°ƒç”¨PythonæœåŠ¡
   - åˆ é™¤å‘é‡æ£€ç´¢ä»£ç 

5. **è¿ç§»è®°å¿†ç³»ç»Ÿ**
   - æ›´æ–°`memory.js`è°ƒç”¨PythonæœåŠ¡
   - åˆ é™¤å‘é‡æ£€ç´¢ä»£ç 

6. **åˆ é™¤Embeddingä»£ç **
   - åˆ é™¤`aistream.js`ä¸­çš„Embeddingç›¸å…³ä»£ç 
   - åˆ é™¤BM25ç®—æ³•

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆåç»­ä¼˜åŒ–ï¼‰

7. **é›†æˆLangChain Agent**
   - AgentæœåŠ¡å®ç°
   - å·¥å…·è°ƒç”¨

8. **æ€§èƒ½ä¼˜åŒ–**
   - ç¼“å­˜æœºåˆ¶
   - æ‰¹é‡å¤„ç†

---

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0  
**æœ€åæ›´æ–°**: 2026-01-13  
**ç»´æŠ¤è€…**: XRK-AGT Team
