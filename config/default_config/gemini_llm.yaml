# ============================================
# Gemini LLM 配置（随端口变化）
# ============================================
# Provider: gemini。Google Generative Language API。
# 位置：data/server_bots/{port}/gemini_llm.yaml

# Google API Key（Generative Language）
apiKey: ""

# API 基础地址（一般不需要改）
baseUrl: "https://generativelanguage.googleapis.com"

# 生成内容接口路径（默认会根据 chatModel 自动拼接）
# 可保留默认；若你需要固定路径，也可手动配置：
# path: "/v1beta/models/gemini-1.5-flash:generateContent"
path: ""

# 模型名称（Gemini: model）
model: "gemini-1.5-flash"

# 生成参数
temperature: 0.7
maxTokens: 4096
topP: 1.0

# Gemini function calling 与 OpenAI 协议不同，本实现默认不注入 MCP tools
enableTools: false

# 请求超时时间（毫秒）
timeout: 360000

# Stream 流式输出配置
# 是否启用流式输出（默认启用）
enableStream: true

# 额外请求头（可选）
headers: {}

# 额外请求体字段（原样合并到 payload 顶层；高级用法）
extraBody: {}

# 代理配置（可选）
# 用于为 Gemini 请求配置 HTTP(S) 代理
# 示例：
# proxy:
#   enabled: true
#   url: "http://127.0.0.1:7890"
proxy: {}
