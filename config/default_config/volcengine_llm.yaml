# ============================================
# 火山引擎 LLM 工厂配置（随端口变化）
# ============================================
# 此配置文件为火山引擎豆包大语言模型配置，每个端口有独立的配置
# 位置：data/server_bots/{port}/volcengine_llm.yaml
# 注意：仅文本模型，识图配置已拆分到 volcengine_vision.yaml

# ----------------------------------------
# API 基础配置
# ----------------------------------------
# API基础地址
baseUrl: "https://ark.cn-beijing.volces.com/api/v3"
# API密钥
apiKey: ""
# 区域（region）
region: "cn-beijing"

# ----------------------------------------
# 模型配置
# ----------------------------------------
# 文本聊天模型
chatModel: "doubao-pro-4k"

# ----------------------------------------
# API 参数配置
# ----------------------------------------
# 温度参数（0-2），值越高越随机
temperature: 0.8
# 最大输出token数
maxTokens: 4000
# Top-p采样（0-1）
topP: 0.9
# 请求超时时间（毫秒）
timeout: 360000

# ----------------------------------------
# 接口路径配置
# ----------------------------------------
# 聊天完成接口路径
path: "/chat/completions"
