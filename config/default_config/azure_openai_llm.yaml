# ============================================
# Azure OpenAI LLM 配置（随端口变化）
# ============================================
# Provider: azure_openai。Chat Completions。
# 位置：data/server_bots/{port}/azure_openai_llm.yaml

apiKey: ""

# Azure endpoint，例如：https://xxxx.openai.azure.com
baseUrl: ""

# Azure 部署名（deployment），必填
deployment: ""

# API 版本（会作为 ?api-version=...）
apiVersion: "2024-10-21"

# 可选：覆盖默认 path（通常无需改）
path: ""

temperature: 0.7
maxTokens: 4096
topP: 1.0
presencePenalty: 0
frequencyPenalty: 0

# 工具调用（MCP）
enableTools: true
toolChoice: "auto"
# 最大工具调用轮次（默认 7，给模型一定的纠错空间，仍有限制防止死循环）
maxToolRounds: 7

# 并行工具调用（若服务端不支持会忽略）
parallelToolCalls: true

# 请求超时时间（毫秒）
timeout: 360000

# Stream 流式输出配置
# 是否启用流式输出（默认启用）
enableStream: true

headers: {}
extraBody: {}

# 代理配置（可选）
# 用于为 Azure OpenAI 请求配置 HTTP(S) 代理
# 示例：
# proxy:
#   enabled: true
#   url: "http://127.0.0.1:7890"
proxy: {}
