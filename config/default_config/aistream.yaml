# ============================================
# AI 工作流配置（全局配置）
# ============================================
# 全局配置，不随服务器端口变化。控制工作流开关、LLM/ASR/TTS 厂商、MCP、子服务端等。
# 位置：data/server_bots/aistream.yaml
# 包含：工作流开关与目录、全局超时、缓存、LLM/ASR/TTS 厂商选择、MCP、Python 子服务端。

# ----------------------------------------
# 工作流系统
# ----------------------------------------
enabled: true
# 工作流脚本目录（相对于项目根）
streamDir: "core/stream"

# ----------------------------------------
# 工作流全局
# ----------------------------------------
global:
  maxTimeout: 360000   # 单次执行最大超时（毫秒）
  debug: false
  maxConcurrent: 5     # 最大并发执行数

# ----------------------------------------
# 工作流缓存
# ----------------------------------------
cache:
  enabled: true
  ttl: 300             # 缓存过期时间（秒）
  maxSize: 100

# ----------------------------------------
# LLM 厂商
# ----------------------------------------
# 可选：volcengine、xiaomimimo、openai、openai_compat、gemini、anthropic、azure_openai。详细配置见 data/server_bots/{port}/*_llm.yaml
llm:
  Provider: volcengine
  timeout: 360000      # 请求超时（毫秒）
  retry:
    enabled: true
    maxAttempts: 3
    delay: 2000        # 重试间隔（毫秒）
    retryOn: ["timeout", "network", "5xx"]

# ----------------------------------------
# ASR 厂商
# ----------------------------------------
# 详细配置见 data/server_bots/{port}/volcengine_asr.yaml
asr:
  Provider: volcengine

# ----------------------------------------
# TTS 厂商
# ----------------------------------------
# 详细配置见 data/server_bots/{port}/volcengine_tts.yaml。onlyForASR：true 表示仅 ASR 触发时才 TTS
tts:
  Provider: volcengine
  onlyForASR: true

# ----------------------------------------
# MCP 服务
# ----------------------------------------
# Model Context Protocol：工具调用与跨平台集成。remote 可桥接外部 MCP（stdio/HTTP/SSE/WebSocket）。
mcp:
  enabled: true
  autoRegister: true
  remote:
    enabled: false
    selected: []
    # 远程 MCP 服务器列表。stdio：command/args；HTTP：url + transport: http。示例：
    # - name: bing-search
    #   command: npx
    #   args: ["-y", "bing-cn-mcp"]
    # - name: custom-mcp
    #   url: http://localhost:3000/mcp
    #   transport: http
    servers: []

# ----------------------------------------
# Python 子服务端
# ----------------------------------------
# 提供向量化、数据处理等，与主服务端分离部署。
subserver:
  host: "127.0.0.1"
  port: 8000
  timeout: 30000        # 毫秒

